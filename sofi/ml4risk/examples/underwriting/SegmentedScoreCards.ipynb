{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SegmentedScoreCard Class\n",
    "---\n",
    "\n",
    "**Segmentation** consists the purpose of allowing different scorecards to be built for each subgroups of the population, with the purpose of achieving better perfomrance than a single scorecard could. One assumption is by manually providing segmentation, the scorecard would boost performances either by the aid of nonlinearity, regularization, or else. \n",
    "* Can be segmentated by different categorical attributes. This is essentially an ensemble approach. \n",
    "* consult the [BaggingClassifier](https://github.com/scikit-learn/scikit-learn/blob/2beed5584/sklearn/ensemble/_bagging.py#L433) or any other meta-estimators like GridSearchCV, SelectFromModel\n",
    "* or build a [VotingClassier](https://github.com/scikit-learn/scikit-learn/blob/2beed5584/sklearn/ensemble/_voting.py#L141) that takes in indicators of which component model to be used.\n",
    "    * for each individual scorecard, maybe have a method to output weight\n",
    "    * out voting classifier will normalize the weight from different models, and return result with soft/hard voting.\n",
    "* Consult on [LGBMClassifier](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)\n",
    "* Just need a simplified version of [this](https://github.com/rasbt/mlxtend/blob/master/mlxtend/classifier/ensemble_vote.py)\n",
    "\n",
    "You know what... just build a simplified mlextend code\n",
    "\n",
    "```python\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "import copy\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1,1,1], fit_base_estimators=False)\n",
    "\n",
    "```\n",
    "\n",
    "Receipe\n",
    "---\n",
    "\n",
    "Should this class simply be a Transformer? Or should we make it a Estimator?\n",
    "* do we need a learning function?\n",
    "\n",
    "**SegmentedClassifier should be a Transfomer**\n",
    "\n",
    "Draft from VotingClassifier\n",
    "```python\n",
    "\"\"\"Soft Voting/Majority Rule classifier for unfitted estimators.\n",
    "\n",
    "    Read more in the :ref:`User Guide <voting_classifier>`.\n",
    "    .. versionadded:: 0.17\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimators : list of (str, estimator) tuples\n",
    "        Invoking the ``fit`` method on the ``VotingClassifier`` will fit clones\n",
    "        of those original estimators that will be stored in the class attribute\n",
    "        ``self.estimators_``. An estimator can be set to ``'drop'``\n",
    "        using ``set_params``.\n",
    "        .. versionchanged:: 0.21\n",
    "            ``'drop'`` is accepted. Using None was deprecated in 0.22 and\n",
    "            support was removed in 0.24.\n",
    "    voting : {'hard', 'soft'}, default='hard'\n",
    "        If 'hard', uses predicted class labels for majority rule voting.\n",
    "        Else if 'soft', predicts the class label based on the argmax of\n",
    "        the sums of the predicted probabilities, which is recommended for\n",
    "        an ensemble of well-calibrated classifiers.\n",
    "    weights : array-like of shape (n_classifiers,), default=None\n",
    "        Sequence of weights (`float` or `int`) to weight the occurrences of\n",
    "        predicted class labels (`hard` voting) or class probabilities\n",
    "        before averaging (`soft` voting). Uses uniform weights if `None`.\n",
    "    n_jobs : int, default=None\n",
    "        The number of jobs to run in parallel for ``fit``.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "        .. versionadded:: 0.18\n",
    "    verbose : bool, default=False\n",
    "        If True, the time elapsed while fitting will be printed as it\n",
    "        is completed.\n",
    "        .. versionadded:: 0.23\n",
    "    Attributes\n",
    "    ----------\n",
    "    estimators_ : list of classifiers\n",
    "        The collection of fitted sub-estimators as defined in ``estimators``\n",
    "        that are not 'drop'.\n",
    "    named_estimators_ : :class:`~sklearn.utils.Bunch`\n",
    "        Attribute to access any fitted sub-estimators by name.\n",
    "        .. versionadded:: 0.20\n",
    "    classes_ : array-like of shape (n_predictions,)\n",
    "        The classes labels.\n",
    "    See Also\n",
    "    --------\n",
    "    VotingRegressor : Prediction voting regressor.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "\n",
    "# import check_is_fitted\n",
    "\n",
    "# modules needed\n",
    "# _collect_probas, _predict_proba, predict_proba, transform, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentedClassifier(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    \"\"\" Voting Mechanism to produce Segmented Performances\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clfs: array-like, shape = [n_classifiers]\n",
    "    \n",
    "    voting: str, {'hard', 'soft'} (default='hard')\n",
    "    \n",
    "    weights: array-like, shape = [n_classifiers], optional (default='None')\n",
    "    \n",
    "    verbose: int, optional (default=0)\n",
    "    \n",
    "    use_clones: bool \n",
    "    \n",
    "    fit_base_estimators: bool (default: True)\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_: array-like, shape = [n_predictions]\n",
    "    \n",
    "    clf: array-like, shape = [n_predictions] \n",
    "\n",
    "    clf_: array-like, shape = [n_predictions]\n",
    "    \n",
    "    \"\"\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_basic_py37",
   "language": "python",
   "name": "ml_basic_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
