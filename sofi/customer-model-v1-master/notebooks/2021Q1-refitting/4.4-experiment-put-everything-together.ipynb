{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801d98c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json\n",
    "sys.path.insert(1, \"../../\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import src.monitoring.utils as mu\n",
    "import src.monitoring.monitoring as mntr\n",
    "import rdsutils.score_alignment as sa\n",
    "import src.monitoring.refit as refit\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a268bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = pd.read_feather(\"../../data/combined_all_features/combined_1620872375.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d4064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../../config.json\", \"r\") as f:\n",
    "#     config = json.load(f)\n",
    "\n",
    "# sample_start = config[\"date_sample_start\"]\n",
    "# sample_end = config[\"date_sample_end\"]\n",
    "# static_sample_dates = config[\"static_sample_dates\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a14d4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[[\"target\", \"indeterminate\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a1f5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.sample_date.between(pd.to_datetime(sample_start),\n",
    "#                           pd.to_datetime(sample_end))].sample_date.hist(bins=100, alpha=0.4)\n",
    "\n",
    "# df[df.sample_date > pd.to_datetime(sample_end)].sample_date.hist(bins=10, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65322919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_start = pd.to_datetime(\"2019-02-01\")\n",
    "# train_end = pd.to_datetime(\"2020-12-31\")\n",
    "# valid_dates = [pd.to_datetime(d) for d in [\"2021-01-01\", \"2021-02-01\"]]\n",
    "\n",
    "# train_df = df[df.sample_date.between(train_start, train_end)]\n",
    "# test_df = df[df.sample_date.isin(valid_dates)]\n",
    "# train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5220f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29e29390",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmonth = \"202104\"\n",
    "s3_base_path = f\"s3://sofi-data-science/jxu/money-risk-models/customer-risk-model/monitor/{mmonth}\"\n",
    "train_df = pd.read_parquet(os.path.join(s3_base_path, \"dev_train_scored.parquet\"))\n",
    "test_df = pd.read_parquet(os.path.join(s3_base_path, \"dev_test_scored.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bcb58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = mu.preprocess(train_df)\n",
    "test_df = mu.preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d20a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modeling_df last date: 2020-12-31 00:00:00\n",
      "15556\n",
      "target counts\n",
      "False    4483337\n",
      "True      173421\n",
      "Name: target, dtype: int64\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=116, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=116\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=116, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=116\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Info] Number of positive: 173421, number of negative: 4483337\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.619837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7814\n",
      "[LightGBM] [Info] Number of data points in the train set: 4656758, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037241 -> initscore=-3.252401\n",
      "[LightGBM] [Info] Start training from score -3.252401\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "prev_model_s3_key = \"jxu/money-risk-models/customer-risk-model/models/customer_risk_target_no_giact_time_since_last_link.pkl\"\n",
    "prev_model = mu.read_pickle_from_s3(\"sofi-data-science\", prev_model_s3_key)\n",
    "\n",
    "# with indeterminant\n",
    "clf_w_ind = refit.train(train_df,\n",
    "                  date_col=\"sample_date\",\n",
    "                  indeterminate_col=None)\n",
    "\n",
    "# without indeterminant\n",
    "clf_wo_ind = refit.train(train_df,\n",
    "                  date_col=\"sample_date\",\n",
    "                  indeterminate_col=\"indeterminate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scale by bads anyways\n",
    "import rdsutils.score_alignment as sa\n",
    "\n",
    "############################################\n",
    "# the incumbent model and scaling method\n",
    "############################################\n",
    "\n",
    "test_df[\"pred_incumbent\"] = prev_model.predict_proba(test_df[prev_model.feature_name_])[:,1]\n",
    "test_df[\"score_incumbent\"] = mu.scale_scores(test_df[\"pred_incumbent\"])\n",
    "\n",
    "#############################################\n",
    "# prediction without indeterminates - dropped ind - rescaled\n",
    "############################################\n",
    "\n",
    "test_df[\"pred_wo_ind\"] = clf_wo_ind.predict_proba(test_df[clf_wo_ind.feature_name_])[:,1]\n",
    "test_df[\"score_wo_ind\"] = mu.scale_scores(test_df[\"pred_wo_ind\"])\n",
    "\n",
    "\n",
    "############################################\n",
    "# prediction with indeterminates\n",
    "############################################\n",
    "\n",
    "test_df[\"pred_w_ind\"] = clf_w_ind.predict_proba(test_df[clf_w_ind.feature_name_])[:,1]\n",
    "\n",
    "src_pred = \"pred_w_ind\"\n",
    "tgt_pred = \"pred_incumbent\"\n",
    "target_col = \"target\"\n",
    "\n",
    "br_tbl = sa.get_score_alignment_table(test_df, src_pred, tgt_pred, target_col,\n",
    "                                   br_precision = 3, pred_precision = 3)\n",
    "test_df[src_pred + \"_rescaled\"] = sa.get_aligned_score(test_df, br_tbl, src_pred, tgt_pred,\n",
    "                                                    pred_precision=3)\n",
    "\n",
    "test_df[\"score_w_ind_rescaled\"] = mu.scale_scores(test_df[\"pred_w_ind_rescaled\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dab38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_risk_groups(serie):\n",
    "    return pd.cut(serie.round(), [300, 474, 510, 560, 600, 850], \n",
    "                  right=True, labels=[f'RG{i}' for i in range(1, 6)])\n",
    "\n",
    "test_df['rg_incumbent'] = get_risk_groups(test_df.score_incumbent)\n",
    "test_df['rg_wo_ind'] = get_risk_groups(test_df.score_wo_ind)\n",
    "test_df['rg_w_ind_rescaled'] = get_risk_groups(test_df.score_w_ind_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbfba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_sample_dates = sorted(train_df[train_df.is_static].sample_date.unique())\n",
    "static_sample_dates = [d for d in static_sample_dates if d >= pd.to_datetime(\"2020-01-01\")]\n",
    "static_sample_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb5cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clfs = {}\n",
    "\n",
    "for d in tqdm(static_sample_dates):\n",
    "    dt_str = str(d).split(\"T\")[0]\n",
    "    train_df_ = train_df[train_df.sample_date <= d]\n",
    "        \n",
    "    for ind in [None, \"indeterminate\"]:\n",
    "\n",
    "        clf = refit.train(train_df_, \n",
    "                        date_col=\"sample_date\",\n",
    "                        indeterminate_col=ind)\n",
    "        \n",
    "        if ind is None:\n",
    "            ind_str = \"w_ind\"\n",
    "        elif ind == \"indeterminate\":\n",
    "            ind_str = \"wo_ind\"\n",
    "        elif ind == \"indeterminate_prev\":\n",
    "            ind_str = \"wo_prev_ind\"\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "\n",
    "        clf_name = f\"model_{dt_str}_{ind_str}\"\n",
    "        pred_col = f\"pred_{dt_str}_{ind_str}\"\n",
    "        score_col = f\"score_{dt_str}_{ind_str}\"\n",
    "        test_df[pred_col] = clf.predict_proba(test_df[clf.feature_name_])[:,1]\n",
    "\n",
    "        # save model\n",
    "        clfs[clf_name] = clf\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03f5c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = [c for c in test_df.columns \n",
    "             if \"pred_\" in c and \"_rescaled\" not in c and \"_w_ind\" not in c]\n",
    "score_cols = [c for c in test_df.columns \n",
    "              if \"score_\" in c and \"_rescaled\" not in c and \"_w_ind\" not in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "df_ = test_df[test_df.sample_date == pd.to_datetime(\"2021-01-01\")]\n",
    "report = mntr.get_pred_reports(df_, \"target\", pred_cols, dropna=True)\n",
    "display(report.sort_values(\"ap\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ff4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "df_ = test_df[test_df.sample_date == pd.to_datetime(\"2021-02-01\")]\n",
    "report = mntr.get_pred_reports(df_, \"target\", pred_cols, dropna=True)\n",
    "display(report.sort_values(\"ap\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea124a4",
   "metadata": {},
   "source": [
    "### Summary\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0890ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_cols = [\"pred_2020-12-31_wo_ind\",\n",
    "                  \"pred_incumbent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mntr_path = \"./artifacts\"\n",
    "mntr.save_valid_performance_plots(\n",
    "        {\"reduced\": df_}, \"target\", candidate_cols, mntr_path, dropna=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb3bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_distr(df, score1, score2, ax, title):\n",
    "\n",
    "    df[score1].hist(bins=50, alpha=0.4, label=score1, ax=ax)\n",
    "    df[score2].hist(bins=50, alpha=0.4, label=score2, ax=ax)\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d68dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"score_2020-12-31_wo_ind\"] = mu.scale_scores(test_df[\"pred_2020-12-31_wo_ind\"])\n",
    "test_df[\"is_active\"] = (test_df.nr_past_transactions > 0) & (test_df.nr_transactions_30d > 0)\n",
    "\n",
    "# plot 4x4\n",
    "score1 = \"score_incumbent\"\n",
    "score2 = \"score_2020-12-31_wo_ind\"\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(16, 16))\n",
    "\n",
    "df_ = test_df[~test_df.is_active & ~test_df.target]  # inactive good accounts\n",
    "plot_score_distr(df_, score1, score2, axs[0, 0], \"score distr - reduced - in-active - good\")\n",
    "\n",
    "df_ = test_df[~test_df.is_active & test_df.target]  # inactive bad accounts\n",
    "plot_score_distr(df_, score1, score2, axs[0, 1], \"score distr - reduced - in-active - bad\")\n",
    "\n",
    "df_ = test_df[test_df.is_active & ~test_df.target]  # active good accounts\n",
    "plot_score_distr(df_, score1, score2, axs[1, 0], \"score distr - reduced - active - good\")\n",
    "\n",
    "df_ = test_df[test_df.is_active & test_df.target]  # active bad accounts\n",
    "plot_score_distr(df_, score1, score2, axs[1, 1], \"score distr - reduced - active - bad\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bafbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_risk_groups(serie):\n",
    "    return pd.cut(serie.round(), [300, 474, 510, 560, 600, 850], \n",
    "                  right=True, labels=[f'RG{i}' for i in range(1, 6)])\n",
    "\n",
    "test_df[\"rg_incumbent\"] = get_risk_groups(test_df.score_incumbent)\n",
    "test_df[\"rg_2020-12-31_wo_ind\"] = get_risk_groups(test_df[\"score_2020-12-31_wo_ind\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa78178",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_incumbent = \"rg_incumbent\"\n",
    "rg_refit = \"rg_2020-12-31_wo_ind\"\n",
    "table = test_df[[rg_incumbent, rg_refit]].value_counts(normalize=True).sort_index().reset_index()\n",
    "table.columns = [rg_incumbent, rg_refit, 'counts']\n",
    "table = pd.pivot_table(table, values='counts', index=rg_incumbent, \n",
    "                       columns=rg_refit, fill_value=0)\n",
    "fig = plt.figure()\n",
    "sns.heatmap(table, cmap='coolwarm', annot=True, fmt='.6g')\n",
    "plt.title('Risk Group Shift')\n",
    "\n",
    "print(\"ratio of users kept their RG: \", np.trace(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdsutils.swap_set_analysis as ssa\n",
    "fig, ax = ssa.plot_swap_set_bad_rate(test_df, rg_incumbent, rg_refit, \"target\", margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7d2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f68926ad41435d3f71bc53cfde328458a97118c37e1f5b5e9fd4646c23ed0cff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
