{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb27f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json, os, ast\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from smart_open import open\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "\n",
    "sys.path.insert(1, \"../..\")\n",
    "from src.logger import make_logger\n",
    "from src.dataloader import TabularDataloader\n",
    "from src.Trainer import LGBMTrainer, TFTrainer\n",
    "from src.preprocess import Preprocess\n",
    "\n",
    "from rdsutils.feature_selection import mrmr\n",
    "from rdsutils.woe import WOE_Transform\n",
    "from _utils.feature_selection import feature_selection as fs\n",
    "from _utils.performance_eval import performance_eval_v3 as p_eval\n",
    "from rdsutils.feature_selection import FeatureSelector as general_purpose_fsel\n",
    "from src.feature_selection import FeatureSelector  # to be moved to rdsutils\n",
    "\n",
    "# new modules\n",
    "from _utils.sample_weights import get_sample_weight\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34df31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'meta', 'data_columns', 'model_params', 'model_features', 'impute_vals', 'monotone'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight = \"weight\"\n",
    "seed = 42\n",
    "\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "display(config.keys()) \n",
    "\n",
    "gen3_features = config[\"data_columns\"][\"gen3_features\"]\n",
    "gen3_params = config[\"model_params\"][\"gen3_params\"]\n",
    "if \"scale_pos_weight\" in gen3_params:\n",
    "    del gen3_params[\"scale_pos_weight\"]\n",
    "\n",
    "bureau_fts = config[\"data_columns\"][\"bureau_features_cols\"] \n",
    "cat_fts = ['t11_t3d_segid', 't11_t3d_segid_supp'] # config[\"data_columns\"][\"cat_cols\"] \n",
    "prescreen_fts = bureau_fts + cat_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68900349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all_features_dev1', 'all_features_dev2', 'all_features_oot1', 'all_features_oot2', 'subset_dev1', 'subset_dev2'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(config[\"data\"][\"clean\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979a426",
   "metadata": {},
   "source": [
    "#### load data and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc338bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228188, 5131)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 5131)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(215815, 5131)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 5131)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 3min 23s, total: 4min 30s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data dict\n",
    "exp_dict = pd.read_csv(config[\"meta\"][\"exp_dict_path\"])\n",
    "\n",
    "# fsel data - sampled\n",
    "dl1 = TabularDataloader(train_path=config[\"data\"][\"clean\"][\"subset_dev1\"])\n",
    "dl1.load_data(debug_size=10000, random_state=seed)\n",
    "\n",
    "debug_df1, _, _ = dl1.get_data(debug=True)\n",
    "train_df1, _, _ = dl1.get_data(debug=False)\n",
    "display(train_df1.shape, debug_df1.shape)\n",
    "\n",
    "dl2 = TabularDataloader(train_path=config[\"data\"][\"clean\"][\"subset_dev2\"])\n",
    "dl2.load_data(debug_size=10000, random_state=seed)\n",
    "\n",
    "debug_df2, _, _ = dl2.get_data(debug=True)\n",
    "train_df2, _, _ = dl2.get_data(debug=False)\n",
    "display(train_df2.shape, debug_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04456f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"target\"\n",
    "target_indeterminate = \"indeterminate\"\n",
    "ri_weight = \"weight_ri\"\n",
    "\n",
    "train_df1[target] = train_df1[\"target_v1\"]\n",
    "train_df1[target_indeterminate] = train_df1[\"indeterminate_v1\"]\n",
    "train_df1[ri_weight] = train_df1[\"weight_ri_v1\"]\n",
    "\n",
    "train_df2[target] = train_df2[\"target_v2\"]\n",
    "train_df2[target_indeterminate] = train_df2[\"indeterminate_v2\"]\n",
    "train_df2[ri_weight] = train_df2[\"weight_ri_v2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "543f75d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(444003, 5134)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_df1, train_df2], axis=0)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424f11d",
   "metadata": {},
   "source": [
    "#### get sample weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e43c70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4205/4205 [00:13<00:00, 311.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        added columns:\n",
      "            weight: training sample_weight scaled using provided weights by ri_source\n",
      "                weight_eval * weight_sample\n",
      "        \n",
      "dropping indeterminate col: indeterminate\n"
     ]
    }
   ],
   "source": [
    "col = \"ri_source\"\n",
    "weights = {\"booked\": 1,\n",
    "           \"proxy\": 1,\n",
    "           \"others\": 0.25}\n",
    "\n",
    "assert sorted(train_df[col].unique().tolist()) == sorted(list(weights.keys()))\n",
    "\n",
    "pp = Preprocess(exp_dict)\n",
    "train_df[\"weight_eval\"] = train_df[\"weight_cob\"] * train_df[ri_weight]\n",
    "train_df = pp.transform(train_df, prescreen_fts, weights, \n",
    "                        drop_indeterminate=target_indeterminate, \n",
    "                        existing_weights_col=\"weight_eval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b75c9bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ri_source\n",
       "booked    26191.500\n",
       "others    44596.625\n",
       "proxy     38240.500\n",
       "Name: weight, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ri_source\n",
       "booked     26191.5\n",
       "others    178386.5\n",
       "proxy      38240.5\n",
       "Name: weight_eval, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at weights\n",
    "display(train_df[[\"weight\", \"ri_source\"]].groupby(\"ri_source\")[\"weight\"].sum())\n",
    "display(train_df[[\"weight_eval\", \"ri_source\"]].groupby(\"ri_source\")[\"weight_eval\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4683393e",
   "metadata": {},
   "source": [
    "#### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28a63f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((440466, 5137), (440466,), (440466,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(target, weight)\n",
    "train_df.shape, train_df[target].shape, train_df[weight].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b395fda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_col: target\n",
      "weight_col: weight\n",
      "Preprocessing... generating iv and shaps\n",
      "prepping woe...\n",
      "\u001b[32mAttrs removed--missing pct>99%:  \u001b[0m ['p13_all8162', 'p13_all8163', 'p13_all8380', 'p13_all8723', 'p13_all9222', 'p13_all9223', 'p13_all9230', 'p13_all9239', 'p13_all9240', 'p13_all9249', 'p13_all9260', 'p13_all9280', 'p13_aua8162', 'p13_aua8163', 'p13_bca0401', 'p13_bca5021', 'p13_bca6201', 'p13_col8194', 'p13_hlc5021', 'p13_iln0403', 'p13_mtf8169', 'p13_mtf8656', 'p13_mts8151', 'p13_rpm5020', 'p13_rpm5320', 'p13_rpm5820', 'p13_rpm6160', 'p13_rpm7110', 'p13_rti5020', 'p13_rti5320', 'p13_rti5820', 'p13_uti5030', 'p13_uti5530', 'p13_uti8151', 't11_tall1412', 't11_tall1413', 't11_tall2412', 't11_tcol2556', 't11_tcol2567', 't11_tmti0451', 't11_tmti0452', 't11_tmti0453', 't11_tmti0454', 't11_tmti0455', 't11_tmti0456', 't11_tmti0457', 't11_tmti0458', 't11_tstu0909']\n",
      "processed  4157  num attributes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepping lgbm shap\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepping lgbm mc shap\n",
      "p13_all9130 1 no monotonic direction - probably should filter out\n",
      "p13_all9134 1 no monotonic direction - probably should filter out\n",
      "p13_all9135 1 no monotonic direction - probably should filter out\n",
      "p13_all9138 1 no monotonic direction - probably should filter out\n",
      "p13_all9139 1 no monotonic direction - probably should filter out\n",
      "p13_all9140 1 no monotonic direction - probably should filter out\n",
      "p13_all9141 1 no monotonic direction - probably should filter out\n",
      "p13_all9144 1 no monotonic direction - probably should filter out\n",
      "p13_all9145 1 no monotonic direction - probably should filter out\n",
      "p13_all9148 1 no monotonic direction - probably should filter out\n",
      "p13_all9149 1 no monotonic direction - probably should filter out\n",
      "p13_all9171 1 no monotonic direction - probably should filter out\n",
      "p13_all9177 1 no monotonic direction - probably should filter out\n",
      "p13_all9178 1 no monotonic direction - probably should filter out\n",
      "p13_all9180 1 no monotonic direction - probably should filter out\n",
      "p13_all9187 1 no monotonic direction - probably should filter out\n",
      "p13_all9188 1 no monotonic direction - probably should filter out\n",
      "p13_all9189 1 no monotonic direction - probably should filter out\n",
      "p13_all9330 1 no monotonic direction - probably should filter out\n",
      "p13_all9340 1 no monotonic direction - probably should filter out\n",
      "p13_all9380 1 no monotonic direction - probably should filter out\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering features by logic - experian\n",
      "dropping 530 features : kept 3675 features\n",
      "    reason:  not AA\n",
      "160 features with greater than                 0.95 missing values\n",
      "dropping 160 features : kept 3515 features\n",
      "    reason:  too many missing\n",
      "dropping 585 features : kept 2930 features\n",
      "    reason:  low_iv\n",
      "running many to few\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [19:21<00:00,  5.81s/it]\n",
      "100%|██████████| 200/200 [22:34<00:00,  6.77s/it]\n",
      "100%|██████████| 200/200 [44:12<00:00, 13.26s/it]\n",
      "100%|██████████| 7/7 [00:01<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ranking.csv\n",
      "running fsel on few\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "p13_all9130 1 no monotonic direction - probably should filter out\n",
      "p13_all9134 1 no monotonic direction - probably should filter out\n",
      "p13_all9135 1 no monotonic direction - probably should filter out\n",
      "p13_all9138 1 no monotonic direction - probably should filter out\n",
      "p13_all9139 1 no monotonic direction - probably should filter out\n",
      "p13_all9140 1 no monotonic direction - probably should filter out\n",
      "p13_all9141 1 no monotonic direction - probably should filter out\n",
      "p13_all9144 1 no monotonic direction - probably should filter out\n",
      "p13_all9145 1 no monotonic direction - probably should filter out\n",
      "p13_all9148 1 no monotonic direction - probably should filter out\n",
      "p13_all9149 1 no monotonic direction - probably should filter out\n",
      "p13_all9171 1 no monotonic direction - probably should filter out\n",
      "p13_all9177 1 no monotonic direction - probably should filter out\n",
      "p13_all9178 1 no monotonic direction - probably should filter out\n",
      "p13_all9180 1 no monotonic direction - probably should filter out\n",
      "p13_all9187 1 no monotonic direction - probably should filter out\n",
      "p13_all9188 1 no monotonic direction - probably should filter out\n",
      "p13_all9189 1 no monotonic direction - probably should filter out\n",
      "p13_all9330 1 no monotonic direction - probably should filter out\n",
      "p13_all9340 1 no monotonic direction - probably should filter out\n",
      "p13_all9380 1 no monotonic direction - probably should filter out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ranking.csv\n",
      "CPU times: user 3h 31min 18s, sys: 45min 51s, total: 4h 17min 9s\n",
      "Wall time: 2h 17min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# %%capture record\n",
    "\n",
    "nr_to_consider = 200\n",
    "nr_to_select = 200\n",
    "fsel_dir = \"./artifacts/dev_combined_fsel_v2\"\n",
    "\n",
    "fsel = FeatureSelector(train_df, data_dict=exp_dict)\n",
    "rankings = fsel.run(prescreen_fts, target, weight, nr_to_consider, nr_to_select,\n",
    "                    output_dir=fsel_dir, filter_by_logic_expn=True)\n",
    "\n",
    "# with open(\"./artifacts/dev1_fsel_1/log.txt\", \"w\") as f:\n",
    "#     f.write(record.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc483355",
   "metadata": {},
   "source": [
    "##### get fsel results\n",
    "\n",
    "* run `fsel.get_rankings(True)` to get ranking_df of features that is ever selected.\n",
    "\n",
    "\n",
    "##### if computation already made, we can just load it\n",
    "\n",
    "```python\n",
    "# initialte project and load back\n",
    "fsel = FeatureSelector(train_df, data_dict=exp_dict)\n",
    "fsel.load_state_dict(fsel_dir)\n",
    "```\n",
    "\n",
    "##### this is the logic underneath fsel.run\n",
    "\n",
    "```python\n",
    "# setup\n",
    "features = prescreen_fts\n",
    "target_col = target\n",
    "weight_col = weight\n",
    "output_dir = fsel_dir\n",
    "corr_threshold = 0.8\n",
    "filter_by_logic_expn = True\n",
    "\n",
    "# first preprocessing\n",
    "fsel.preprocess(features, target_col, weight_col, output_dir=output_dir)\n",
    "\n",
    "if filter_by_logic_expn:\n",
    "    print(\"filtering features by logic - experian\")\n",
    "    features = fsel.filter_by_logic_expn(features, target_col, weight_col)\n",
    "\n",
    "fsel.many_to_few(features, target_col, weight_col, nr_to_consider)\n",
    "if output_dir: fsel.save_state_dict(output_dir)\n",
    "\n",
    "# get top <nr_to_select> features by mean just as a rule of a thumb\n",
    "rankings_imp = fsel.get_rankings(True)\n",
    "rankings_imp[\"<mean>\"] = rankings_imp.mean(axis=1)\n",
    "rankings_imp.sort_values(\"<mean>\", inplace=True)\n",
    "top_features = rankings_imp.index.to_list()\n",
    "rankings_imp.drop(\"<mean>\", axis=1, inplace=True)\n",
    "\n",
    "# to approximate number of features to consider so\n",
    "# we end up nr_to_select features when using the less efficient \n",
    "# methods\n",
    "\n",
    "approx_nr_to_select = int(nr_to_select / (corr_threshold+0.001))\n",
    "\n",
    "fsel.fsel_on_few(top_features[:approx_nr_to_select], target_col, \n",
    "                 weight_col, corr_threshold=corr_threshold)\n",
    "if output_dir: fsel.save_state_dict(output_dir)\n",
    "\n",
    "rankings = fsel.get_rankings(False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "929f6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsel_dir = \"./artifacts/dev_combined_fsel_v2\"\n",
    "fsel2 = FeatureSelector(train_df, data_dict=exp_dict)\n",
    "fsel2.load_state_dict(fsel_dir)\n",
    "fts = fsel2.get_rankings(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43fa1f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mrmr_shapcq_mc</th>\n",
       "      <th>mrmr_shapcq</th>\n",
       "      <th>mrmr_ivcq</th>\n",
       "      <th>lgbm_shap_214</th>\n",
       "      <th>lgbm_shap_mc_214</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p13_alj0416</th>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>2930</td>\n",
       "      <td>159</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p13_alj5320</th>\n",
       "      <td>66</td>\n",
       "      <td>95</td>\n",
       "      <td>2930</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p13_alj8120</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2930</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p13_all2002</th>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>183</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p13_all2180</th>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>39</td>\n",
       "      <td>214</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t11_tstu3755</th>\n",
       "      <td>2930</td>\n",
       "      <td>171</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t11_tstu4701</th>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>2930</td>\n",
       "      <td>92</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t11_tstu4704</th>\n",
       "      <td>2930</td>\n",
       "      <td>196</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t11_tstu4752</th>\n",
       "      <td>87</td>\n",
       "      <td>89</td>\n",
       "      <td>2930</td>\n",
       "      <td>135</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t11_tstu4755</th>\n",
       "      <td>92</td>\n",
       "      <td>82</td>\n",
       "      <td>2930</td>\n",
       "      <td>116</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              mrmr_shapcq_mc  mrmr_shapcq  mrmr_ivcq  lgbm_shap_214  \\\n",
       "p13_alj0416               63           65       2930            159   \n",
       "p13_alj5320               66           95       2930             48   \n",
       "p13_alj8120                3            3       2930             22   \n",
       "p13_all2002             2930         2930        183           2930   \n",
       "p13_all2180             2930         2930         39            214   \n",
       "...                      ...          ...        ...            ...   \n",
       "t11_tstu3755            2930          171       2930           2930   \n",
       "t11_tstu4701              34           36       2930             92   \n",
       "t11_tstu4704            2930          196       2930           2930   \n",
       "t11_tstu4752              87           89       2930            135   \n",
       "t11_tstu4755              92           82       2930            116   \n",
       "\n",
       "              lgbm_shap_mc_214  \n",
       "p13_alj0416                146  \n",
       "p13_alj5320                 28  \n",
       "p13_alj8120                  1  \n",
       "p13_all2002               2930  \n",
       "p13_all2180                129  \n",
       "...                        ...  \n",
       "t11_tstu3755              2930  \n",
       "t11_tstu4701                56  \n",
       "t11_tstu4704              2930  \n",
       "t11_tstu4752               125  \n",
       "t11_tstu4755                86  \n",
       "\n",
       "[423 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d2812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7574713",
   "metadata": {},
   "source": [
    "#### build base model, set on features\n",
    "\n",
    "# issue: feature selector did not consider categorical variables.... since we only have < 5 of them, treat manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d373520",
   "metadata": {},
   "source": [
    "#### hyperparam tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1810573a",
   "metadata": {},
   "source": [
    "#### model eval\n",
    "---\n",
    "* evaluation segments\n",
    "    * `weight`\n",
    "    * around score cut\n",
    "    * booked, proxy, others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9a48599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2868, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings = pd.read_csv(\"./artifacts/dev1_fsel_v1/ranking.csv\", index_col=0)\n",
    "rankings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef4ae0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target indeterminate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    440466\n",
       "Name: indeterminate, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n"
     ]
    }
   ],
   "source": [
    "# hand made shap\n",
    "\n",
    "import shap\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(target, target_indeterminate)\n",
    "display(train_df[target_indeterminate].value_counts())\n",
    "\n",
    "default_params = {\n",
    " 'objective': 'binary',\n",
    " 'metric': 'auc',\n",
    " 'boosting': 'gbdt',\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.05,\n",
    " 'min_data_in_leaf': [300],\n",
    " 'verbosity': -1,\n",
    " 'seed': 157,\n",
    " 'n_jobs': 30,\n",
    " 'n_estimators': 1000\n",
    "}\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(**default_params)\n",
    "\n",
    "list_features = rankings.index.to_list()\n",
    "trainer = LGBMTrainer()\n",
    "trainer.train(lgbm, \n",
    "              train_df,\n",
    "              features = list_features,\n",
    "              target_col = target,\n",
    "              sample_weight = train_df[weight]\n",
    "             )\n",
    "explainer = shap.TreeExplainer(lgbm)\n",
    "shap_values = explainer.shap_values(train_df[list_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a78be5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap_features = pd.DataFrame(shap_values[1], columns=list(train_df[list_features]))\\\n",
    "                    .apply(lambda x: np.abs(x).mean(), axis=0)\\\n",
    "                    .sort_values(ascending=False)\n",
    "\n",
    "benchmark_fts = shap_features.index.to_list()[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d741cc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "features = benchmark_fts\n",
    "from rdsutils.feature_selection.WeightedCorr import WeightedCorr\n",
    "\n",
    "corr_matrix = WeightedCorr(df=train_df[benchmark_fts+[weight]], wcol=weight)(\"pearson\").abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "reduced_shap_features = [f for f in features if f not in (to_drop)]\n",
    "print(len(reduced_shap_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ef901d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reduced_shap_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4da58c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./artifacts/models/model_params.json\", \"r\") as f:\n",
    "    model_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c82efab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p13_all9123 1\n",
      "p13_all9130 1\n",
      "p13_all9134 1\n",
      "p13_all9135 1\n",
      "p13_all9138 1\n",
      "p13_all9139 1\n",
      "p13_all9140 1\n",
      "p13_all9141 1\n",
      "p13_all9144 1\n",
      "p13_all9145 1\n",
      "p13_all9148 1\n",
      "p13_all9149 1\n",
      "p13_all9171 1\n",
      "p13_all9177 1\n",
      "p13_all9178 1\n",
      "p13_all9180 1\n",
      "p13_all9187 1\n",
      "p13_all9188 1\n",
      "p13_all9189 1\n",
      "p13_all9330 1\n",
      "p13_all9340 1\n",
      "p13_all9380 1\n"
     ]
    }
   ],
   "source": [
    "def get_monotone_dir(woe_dict):\n",
    "    result = {}\n",
    "    for k in woe_dict:\n",
    "        tbl = woe_dict[k]\n",
    "        if len(tbl) < 2:\n",
    "            print(k, len(tbl))\n",
    "        elif tbl.iloc[0][\"woe\"] < tbl.iloc[1][\"woe\"]:\n",
    "            direction = 1\n",
    "        else:\n",
    "            direction = -1\n",
    "        \n",
    "        result[k] = direction\n",
    "    return result\n",
    "\n",
    "with open(\"./artifacts/dev2_fsel_v2/woe_dict.pkl\", \"rb\") as f:\n",
    "    woe_dict = pkl.load(f)\n",
    "\n",
    "monotone_dict = get_monotone_dir(woe_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ebb36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fts_ = reduced_shap_features[:32]\n",
    "params_ = copy.deepcopy(model_params[\"dev2_v2_benchmark\"][\"params\"])\n",
    "\n",
    "fts_mc = fts_\n",
    "params_mc = copy.deepcopy(params_)\n",
    "mc = [monotone_dict[ft] for ft in fts_mc]\n",
    "params_mc[\"monotone_constraints\"] = mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c756e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_v2_benchmark = {\"features\": fts_,\n",
    "                     \"params\": params_,\n",
    "                     \"model_type\": \"lightgbm\"}\n",
    "combined_v2_benchmark_mc = {\"features\": fts_mc,\n",
    "                     \"params\": params_mc,\n",
    "                     \"model_type\": \"lightgbm\"}\n",
    "model_params[\"combined_v2_benchmark\"] = combined_v2_benchmark\n",
    "model_params[\"combined_v2_benchmark_mc\"] = combined_v2_benchmark_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1470287b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dev1_v1_benchmark', 'dev1_v1_benchmark_mc', 'dev1_v1_fsel_32', 'dev1_v1_fsel_32_mc', 'dev2_v2_benchmark', 'dev2_v2_benchmark_mc', 'dev2_v1_benchmark', 'dev2_v1_benchmark_mc', 'combined_v1_benchmark', 'combined_v1_benchmark_mc', 'combined_v2_benchmark', 'combined_v2_benchmark_mc'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19e916b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./artifacts/models/model_params.json\", \"w\") as f:\n",
    "    json.dump(model_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134be315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114717ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pl_gen4",
   "language": "python",
   "name": "conda_pl_gen4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
