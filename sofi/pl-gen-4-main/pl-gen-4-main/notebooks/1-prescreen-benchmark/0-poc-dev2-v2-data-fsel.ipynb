{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ef58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json, os, ast\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from smart_open import open\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "\n",
    "sys.path.insert(1, \"../..\")\n",
    "from src.logger import make_logger\n",
    "from src.dataloader import TabularDataloader\n",
    "from src.Trainer import LGBMTrainer, TFTrainer\n",
    "from src.preprocess import Preprocess\n",
    "\n",
    "from rdsutils.feature_selection import mrmr\n",
    "from rdsutils.woe import WOE_Transform\n",
    "from _utils.feature_selection import feature_selection as fs\n",
    "from _utils.performance_eval import performance_eval_v3 as p_eval\n",
    "from rdsutils.feature_selection import FeatureSelector as general_purpose_fsel\n",
    "from src.feature_selection import FeatureSelector  # to be moved to rdsutils\n",
    "\n",
    "# new modules\n",
    "from _utils.sample_weights import get_sample_weight\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59dfddfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'meta', 'data_columns', 'model_params', 'model_features', 'impute_vals', 'monotone'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = 'target_v2'\n",
    "target_indeterminate = 'indeterminate_v2'\n",
    "weight = \"weight\"\n",
    "seed = 42\n",
    "\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "display(config.keys()) \n",
    "\n",
    "gen3_features = config[\"data_columns\"][\"gen3_features\"]\n",
    "gen3_params = config[\"model_params\"][\"gen3_params\"]\n",
    "if \"scale_pos_weight\" in gen3_params:\n",
    "    del gen3_params[\"scale_pos_weight\"]\n",
    "\n",
    "bureau_fts = config[\"data_columns\"][\"bureau_features_cols\"] \n",
    "cat_fts = ['t11_t3d_segid', 't11_t3d_segid_supp'] # config[\"data_columns\"][\"cat_cols\"] \n",
    "prescreen_fts = bureau_fts + cat_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920c2960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all_features_dev1', 'all_features_dev2', 'all_features_oot1', 'all_features_oot2', 'subset_dev1', 'subset_dev2'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(config[\"data\"][\"clean\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93383e9",
   "metadata": {},
   "source": [
    "#### load data and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b877246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 s, sys: 1min 48s, total: 2min 20s\n",
      "Wall time: 44.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((215815, 5131), (10000, 5131))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# data dict\n",
    "exp_dict = pd.read_csv(config[\"meta\"][\"exp_dict_path\"])\n",
    "\n",
    "# fsel data - sampled\n",
    "dl = TabularDataloader(train_path=config[\"data\"][\"clean\"][\"subset_dev2\"])\n",
    "dl.load_data(debug_size=10000, random_state=seed)\n",
    "\n",
    "debug_df, _, _ = dl.get_data(debug=True)\n",
    "train_df, _, _ = dl.get_data(debug=False)\n",
    "train_df.shape, debug_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d89dca",
   "metadata": {},
   "source": [
    "#### get sample weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2740b4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4205/4205 [00:09<00:00, 427.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        added columns:\n",
      "            weight: training sample_weight scaled using provided weights by ri_source\n",
      "                weight_eval * weight_sample\n",
      "        \n",
      "dropping indeterminate col: indeterminate_v2\n",
      "CPU times: user 14.1 s, sys: 4.74 s, total: 18.9 s\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "col = \"ri_source\"\n",
    "weights = {\"booked\": 1,\n",
    "           \"proxy\": 1,\n",
    "           \"others\": 0.25}\n",
    "\n",
    "assert sorted(train_df[col].unique().tolist()) == sorted(list(weights.keys()))\n",
    "\n",
    "pp = Preprocess(exp_dict)\n",
    "train_df[\"weight_eval\"] = train_df[\"weight_cob\"] * train_df[\"weight_ri_v2\"]\n",
    "%time train_df = pp.transform(train_df, prescreen_fts, weights, \n",
    "                              drop_indeterminate=target_indeterminate, \n",
    "                              existing_weights_col=\"weight_eval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac12e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ri_source\n",
       "booked    10581.500\n",
       "others    20378.625\n",
       "proxy     20044.500\n",
       "Name: weight, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ri_source\n",
       "booked    10581.5\n",
       "others    81514.5\n",
       "proxy     20044.5\n",
       "Name: weight_eval, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at weights\n",
    "display(train_df[[\"weight\", \"ri_source\"]].groupby(\"ri_source\")[\"weight\"].sum())\n",
    "display(train_df[[\"weight_eval\", \"ri_source\"]].groupby(\"ri_source\")[\"weight_eval\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453147c",
   "metadata": {},
   "source": [
    "#### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83e65212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_col: target_v2\n",
      "weight_col: weight\n",
      "Preprocessing... generating iv and shaps\n",
      "prepping woe...\n",
      "\u001b[32mAttrs removed--missing pct>99%:  \u001b[0m ['p13_all8162', 'p13_all8163', 'p13_all8380', 'p13_all8723', 'p13_all9222', 'p13_all9223', 'p13_all9230', 'p13_all9239', 'p13_all9240', 'p13_all9249', 'p13_all9260', 'p13_all9280', 'p13_aua8162', 'p13_aua8163', 'p13_bca0401', 'p13_bca5021', 'p13_bca6201', 'p13_col8194', 'p13_hlc5021', 'p13_iln0403', 'p13_mtf8169', 'p13_mtf8656', 'p13_mts8151', 'p13_rpm5020', 'p13_rpm5320', 'p13_rpm5820', 'p13_rpm6160', 'p13_rpm7110', 'p13_rti5020', 'p13_rti5320', 'p13_rti5820', 'p13_uti5030', 'p13_uti5530', 'p13_uti8151', 't11_tall1412', 't11_tall1413', 't11_tall2412', 't11_tcol2556', 't11_tcol2567', 't11_tcol3567', 't11_tmti0451', 't11_tmti0452', 't11_tmti0453', 't11_tmti0454', 't11_tmti0455', 't11_tmti0456', 't11_tmti0457', 't11_tmti0458', 't11_tstu0909']\n",
      "processed  4156  num attributes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepping lgbm shap\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepping lgbm mc shap\n",
      "p13_all9123 1 no monotonic direction - probably should filter out\n",
      "p13_all9130 1 no monotonic direction - probably should filter out\n",
      "p13_all9134 1 no monotonic direction - probably should filter out\n",
      "p13_all9135 1 no monotonic direction - probably should filter out\n",
      "p13_all9138 1 no monotonic direction - probably should filter out\n",
      "p13_all9139 1 no monotonic direction - probably should filter out\n",
      "p13_all9140 1 no monotonic direction - probably should filter out\n",
      "p13_all9141 1 no monotonic direction - probably should filter out\n",
      "p13_all9144 1 no monotonic direction - probably should filter out\n",
      "p13_all9145 1 no monotonic direction - probably should filter out\n",
      "p13_all9148 1 no monotonic direction - probably should filter out\n",
      "p13_all9149 1 no monotonic direction - probably should filter out\n",
      "p13_all9171 1 no monotonic direction - probably should filter out\n",
      "p13_all9177 1 no monotonic direction - probably should filter out\n",
      "p13_all9178 1 no monotonic direction - probably should filter out\n",
      "p13_all9180 1 no monotonic direction - probably should filter out\n",
      "p13_all9187 1 no monotonic direction - probably should filter out\n",
      "p13_all9188 1 no monotonic direction - probably should filter out\n",
      "p13_all9189 1 no monotonic direction - probably should filter out\n",
      "p13_all9330 1 no monotonic direction - probably should filter out\n",
      "p13_all9340 1 no monotonic direction - probably should filter out\n",
      "p13_all9380 1 no monotonic direction - probably should filter out\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering features by logic - experian\n",
      "dropping 530 features : kept 3675 features\n",
      "    reason:  not AA\n",
      "162 features with greater than                 0.95 missing values\n",
      "dropping 162 features : kept 3513 features\n",
      "    reason:  too many missing\n",
      "dropping 565 features : kept 2948 features\n",
      "    reason:  low_iv\n",
      "running many to few\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [09:47<00:00,  2.94s/it]\n",
      "100%|██████████| 200/200 [12:01<00:00,  3.61s/it]\n",
      "100%|██████████| 200/200 [23:49<00:00,  7.15s/it]\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ranking.csv\n",
      "running fsel on few\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "p13_all9123 1 no monotonic direction - probably should filter out\n",
      "p13_all9130 1 no monotonic direction - probably should filter out\n",
      "p13_all9134 1 no monotonic direction - probably should filter out\n",
      "p13_all9135 1 no monotonic direction - probably should filter out\n",
      "p13_all9138 1 no monotonic direction - probably should filter out\n",
      "p13_all9139 1 no monotonic direction - probably should filter out\n",
      "p13_all9140 1 no monotonic direction - probably should filter out\n",
      "p13_all9141 1 no monotonic direction - probably should filter out\n",
      "p13_all9144 1 no monotonic direction - probably should filter out\n",
      "p13_all9145 1 no monotonic direction - probably should filter out\n",
      "p13_all9148 1 no monotonic direction - probably should filter out\n",
      "p13_all9149 1 no monotonic direction - probably should filter out\n",
      "p13_all9171 1 no monotonic direction - probably should filter out\n",
      "p13_all9177 1 no monotonic direction - probably should filter out\n",
      "p13_all9178 1 no monotonic direction - probably should filter out\n",
      "p13_all9180 1 no monotonic direction - probably should filter out\n",
      "p13_all9187 1 no monotonic direction - probably should filter out\n",
      "p13_all9188 1 no monotonic direction - probably should filter out\n",
      "p13_all9189 1 no monotonic direction - probably should filter out\n",
      "p13_all9330 1 no monotonic direction - probably should filter out\n",
      "p13_all9340 1 no monotonic direction - probably should filter out\n",
      "p13_all9380 1 no monotonic direction - probably should filter out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ranking.csv\n",
      "CPU times: user 1h 41min 37s, sys: 22min 48s, total: 2h 4min 25s\n",
      "Wall time: 1h 4min 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# %%capture record\n",
    "\n",
    "nr_to_consider = 200\n",
    "nr_to_select = 50\n",
    "fsel_dir = \"./artifacts/dev2_fsel_2\"\n",
    "\n",
    "fsel = FeatureSelector(train_df, data_dict=exp_dict)\n",
    "rankings = fsel.run(prescreen_fts, target, weight, nr_to_consider, nr_to_select,\n",
    "                    output_dir=fsel_dir, filter_by_logic_expn=True)\n",
    "\n",
    "# with open(\"./artifacts/dev1_fsel_1/log.txt\", \"w\") as f:\n",
    "#     f.write(record.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4fe77",
   "metadata": {},
   "source": [
    "##### get fsel results\n",
    "\n",
    "* run `fsel.get_rankings(True)` to get ranking_df of features that is ever selected.\n",
    "\n",
    "\n",
    "##### if computation already made, we can just load it\n",
    "\n",
    "```python\n",
    "# initialte project and load back\n",
    "fsel = FeatureSelector(train_df, data_dict=exp_dict)\n",
    "fsel.load_state_dict(fsel_dir)\n",
    "```\n",
    "\n",
    "##### this is the logic underneath fsel.run\n",
    "\n",
    "```python\n",
    "# setup\n",
    "features = prescreen_fts\n",
    "target_col = target\n",
    "weight_col = weight\n",
    "output_dir = fsel_dir\n",
    "corr_threshold = 0.8\n",
    "filter_by_logic_expn = True\n",
    "\n",
    "# first preprocessing\n",
    "fsel.preprocess(features, target_col, weight_col, output_dir=output_dir)\n",
    "\n",
    "if filter_by_logic_expn:\n",
    "    print(\"filtering features by logic - experian\")\n",
    "    features = fsel.filter_by_logic_expn(features, target_col, weight_col)\n",
    "\n",
    "fsel.many_to_few(features, target_col, weight_col, nr_to_consider)\n",
    "if output_dir: fsel.save_state_dict(output_dir)\n",
    "\n",
    "# get top <nr_to_select> features by mean just as a rule of a thumb\n",
    "rankings_imp = fsel.get_rankings(True)\n",
    "rankings_imp[\"<mean>\"] = rankings_imp.mean(axis=1)\n",
    "rankings_imp.sort_values(\"<mean>\", inplace=True)\n",
    "top_features = rankings_imp.index.to_list()\n",
    "rankings_imp.drop(\"<mean>\", axis=1, inplace=True)\n",
    "\n",
    "# to approximate number of features to consider so\n",
    "# we end up nr_to_select features when using the less efficient \n",
    "# methods\n",
    "\n",
    "approx_nr_to_select = int(nr_to_select / (corr_threshold+0.001))\n",
    "\n",
    "fsel.fsel_on_few(top_features[:approx_nr_to_select], target_col, \n",
    "                 weight_col, corr_threshold=corr_threshold)\n",
    "if output_dir: fsel.save_state_dict(output_dir)\n",
    "\n",
    "rankings = fsel.get_rankings(False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fc051a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsel2 = FeatureSelector(train_df, data_dict=exp_dict)\n",
    "fsel2.load_state_dict(fsel_dir)\n",
    "fts = fsel2.get_rankings(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7bfa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df8734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a16ea81",
   "metadata": {},
   "source": [
    "#### build base model, set on features\n",
    "\n",
    "# issue: feature selector did not consider categorical variables.... since we only have < 5 of them, treat manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d956bd2",
   "metadata": {},
   "source": [
    "#### hyperparam tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d040b",
   "metadata": {},
   "source": [
    "#### model eval\n",
    "---\n",
    "* evaluation segments\n",
    "    * `weight`\n",
    "    * around score cut\n",
    "    * booked, proxy, others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48e96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand made shap\n",
    "\n",
    "import shap\n",
    "import lightgbm as lgb\n",
    "\n",
    "default_params = {\n",
    " 'objective': 'binary',\n",
    " 'metric': 'auc',\n",
    " 'boosting': 'gbdt',\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.05,\n",
    " 'min_data_in_leaf': [300],\n",
    " 'verbosity': -1,\n",
    " 'seed': 157,\n",
    " 'n_jobs': 30,\n",
    " 'n_estimators': 1000\n",
    "}\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(**default_params)\n",
    "\n",
    "list_features = rankings.index.to_list()\n",
    "trainer = LGBMTrainer()\n",
    "trainer.train(lgbm, \n",
    "              train_df,\n",
    "              features = list_features,\n",
    "              target_col = target,\n",
    "              sample_weight = train_df[weight]\n",
    "             )\n",
    "explainer = shap.TreeExplainer(lgbm)\n",
    "shap_values = explainer.shap_values(train_df[list_features])\n",
    "\n",
    "shap_features = pd.DataFrame(shap_values[1], columns=list(train_df[list_features]))\\\n",
    "                    .apply(lambda x: np.abs(x).mean(), axis=0)\\\n",
    "                    .sort_values(ascending=False)\n",
    "\n",
    "benchmark_fts = shap_features.index.to_list()[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "557d4869",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap_features = pd.DataFrame(shap_values[1], columns=list(train_df[list_features]))\\\n",
    "                    .apply(lambda x: np.abs(x).mean(), axis=0)\\\n",
    "                    .sort_values(ascending=False)\n",
    "\n",
    "benchmark_fts = shap_features.index.to_list()[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01a76c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "features = benchmark_fts\n",
    "from rdsutils.feature_selection.WeightedCorr import WeightedCorr\n",
    "\n",
    "corr_matrix = WeightedCorr(df=train_df[benchmark_fts+[weight]], wcol=weight)(\"pearson\").abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "reduced_shap_features = [f for f in features if f not in (to_drop)]\n",
    "print(len(reduced_shap_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ce53c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reduced_shap_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4315f4d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_57104/805096824.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./artifacts/models/model_params.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"./artifacts/models/model_params.json\", \"r\") as f:\n",
    "    model_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ab3e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "fts_ = reduced_shap_features[:32]\n",
    "params_ = copy.deepcopy(model_params[\"dev1_v1_benchmark\"][\"params\"])\n",
    "\n",
    "fts_mc = fts_\n",
    "params_mc = copy.deepcopy(params_)\n",
    "params_mc[\"monotone_constraints\"] = mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b619b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev2_v2_benchmark = {\"features\": fts_,\n",
    "                     \"params\": params_,\n",
    "                     \"model_type\": \"lightgbm\"}\n",
    "dev2_v2_benchmark_mc = {\"features\": fts_mc,\n",
    "                     \"params\": params_mc,\n",
    "                     \"model_type\": \"lightgbm\"}\n",
    "model_params[\"dev2_v2_benchmark\"] = dev2_v2_benchmark\n",
    "model_params[\"dev2_v2_benchmark_mc\"] = dev2_v2_benchmark_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11c6051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./artifacts/models/model_params.json\", \"w\") as f:\n",
    "    json.dump(model_params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f4a7502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p13_all9123 1\n",
      "p13_all9130 1\n",
      "p13_all9134 1\n",
      "p13_all9135 1\n",
      "p13_all9138 1\n",
      "p13_all9139 1\n",
      "p13_all9140 1\n",
      "p13_all9141 1\n",
      "p13_all9144 1\n",
      "p13_all9145 1\n",
      "p13_all9148 1\n",
      "p13_all9149 1\n",
      "p13_all9171 1\n",
      "p13_all9177 1\n",
      "p13_all9178 1\n",
      "p13_all9180 1\n",
      "p13_all9187 1\n",
      "p13_all9188 1\n",
      "p13_all9189 1\n",
      "p13_all9330 1\n",
      "p13_all9340 1\n",
      "p13_all9380 1\n"
     ]
    }
   ],
   "source": [
    "def get_monotone_dir(woe_dict):\n",
    "    result = {}\n",
    "    for k in woe_dict:\n",
    "        tbl = woe_dict[k]\n",
    "        if len(tbl) < 2:\n",
    "            print(k, len(tbl))\n",
    "        elif tbl.iloc[0][\"woe\"] < tbl.iloc[1][\"woe\"]:\n",
    "            direction = 1\n",
    "        else:\n",
    "            direction = -1\n",
    "        \n",
    "        result[k] = direction\n",
    "    return result\n",
    "\n",
    "with open(\"./artifacts/dev2_fsel_v2/woe_dict.pkl\", \"rb\") as f:\n",
    "    woe_dict = pkl.load(f)\n",
    "\n",
    "monotone_dict = get_monotone_dir(woe_dict)\n",
    "mc = [monotone_dict[ft] for ft in fts_mc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f225ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0dc859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pl_gen4",
   "language": "python",
   "name": "conda_pl_gen4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
