{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550e3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import autogluon as ag\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b169cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"./artifacts/train_df_for_hypertune.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "028ed691",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"target_v1\"\n",
    "target_indeterminate = 'indeterminate_v1'\n",
    "weight_col = \"weight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39300f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# train_df, test_df = train_test_split(data, train_size=0.8, stratify=data[target], random_state=seed)\n",
    "# train_df, valid_df = train_test_split(train_df, train_size=0.75, stratify=train_df[target], random_state=seed)\n",
    "train_df, valid_df = train_test_split(data, train_size=0.75, stratify=data[target], random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b44646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1706685, 244), (568895, 244))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, valid_df.shape# , test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34cd8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = pd.read_csv(\"./artifacts/fsel-ranking.csv\", index_col=0)\n",
    "ranking[\"rank_mean\"] = ranking.mean(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f493cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_features(feature_ranking, rank_col, k):\n",
    "    s = feature_ranking[rank_col].sort_values().head(k)\n",
    "    return s.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "460b9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_fts = get_top_k_features(ranking, \"rank_mean\", 32)\n",
    "\n",
    "with open(\"./artifacts/candidatte_features.json\", \"r\") as f:\n",
    "    combined_fts = json.load(f)[\"combined_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15d63fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = combined_fts\n",
    "id_col = \"id\"\n",
    "meta_cols = [target, id_col]\n",
    "train_data = TabularDataset(train_df[features+[target, weight_col]])\n",
    "valid_data = TabularDataset(valid_df[features+[target, weight_col]])\n",
    "# test_data = TabularDataset(test_df[features+[target, weight_col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d335dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'roc_auc'   # 'roc_auc', 'f1', 'average_precision'\n",
    "auto_stack = True\n",
    "path = './artifacts/autogluon-prescreen'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "hp_tune = True\n",
    "time_limits = 120*60  # 2mins\n",
    "\n",
    "# GBM\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'objective' : 'binary',\n",
    "    'metric' : 'auc',\n",
    "    'boosting': 'gbdt',\n",
    "    'tree_learner': 'serial',\n",
    "    'boost_from_average': 'false',\n",
    "    'tree_learner': 'feature',\n",
    "    'num_leaves' : ag.core.space.Int(lower=5, upper=100, default=10),\n",
    "    'lambda_l1': ag.core.space.Real(lower=0, upper=30, default=5),\n",
    "    'lambda_l2': ag.core.space.Real(lower=0, upper=30, default=5),\n",
    "    'min_data_in_leaf': ag.core.space.Int(lower=10, upper=200, default=30),\n",
    "    'max_depth' : ag.core.space.Int(lower=2, upper=7, default=3),\n",
    "    'num_boost_round': ag.core.space.Int(lower=100, upper=2000, default=1000),\n",
    "    'learning_rate': ag.core.space.Real(1e-3, 1e-1, default=1e-2),\n",
    "    'feature_fraction' : ag.core.space.Real(0.1, 0.8, default=0.5),\n",
    "    'early_stopping_round': 200,\n",
    "    'seed': seed,\n",
    "    'seed_value': seed\n",
    "}\n",
    "\n",
    "cat_options = {}  # CAT\n",
    "\n",
    "xgb_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'objective' : 'binary',\n",
    "    'metric' : 'auc',\n",
    "    'boosting': 'gbdt',\n",
    "    'tree_learner': 'serial',\n",
    "    'boost_from_average': 'false',\n",
    "    'tree_learner': 'feature',\n",
    "    'num_leaves' : ag.core.space.Int(lower=5, upper=100, default=10),\n",
    "    'lambda': ag.core.space.Real(lower=0, upper=30, default=5),\n",
    "    'alpha': ag.core.space.Real(lower=0, upper=30, default=5),\n",
    "    'min_data_in_leaf': ag.core.space.Int(lower=10, upper=200, default=30),\n",
    "    'max_depth' : ag.core.space.Int(lower=2, upper=7, default=3),\n",
    "    'n_estimators': ag.core.space.Int(lower=100, upper=2000, default=1000),\n",
    "    'learning_rate': ag.core.space.Real(1e-3, 1e-1, default=1e-2),\n",
    "    'feature_fraction' : ag.core.space.Real(0.1, 0.8, default=0.5),\n",
    "    'early_stopping_round': 200,\n",
    "    'seed': seed,\n",
    "    'seed_value': seed\n",
    "}  # XT \n",
    "\n",
    "# try TRANSF later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5aad453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./artifacts/autogluon-prescreen\"\n"
     ]
    }
   ],
   "source": [
    "tp = TabularPredictor(label=target,\n",
    "                      problem_type=\"binary\", \n",
    "                      eval_metric=metric,\n",
    "                      sample_weight=weight_col,\n",
    "                      path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "399ca26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Values in column 'weight' used as sample weights instead of predictive features. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "Beginning AutoGluon training ... Time limit = 7200s\n",
      "AutoGluon will save models to \"./artifacts/autogluon-prescreen/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    1706685\n",
      "Train Data Columns: 33\n",
      "Tuning Data Rows:    568895\n",
      "Tuning Data Columns: 33\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    297281.67 MB\n",
      "\tTrain Data (Original)  Memory Usage: 582.55 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 19 | ['p13_iqt9536', 'p13_bcc5520', 'p13_alx5039', 't11_taxm2203', 'p13_all5120', ...]\n",
      "\t\t('int', [])   : 13 | ['trended3d_tbca3275', 'p13_iqz9425', 'p13_iln8320', 'trended3d_tbca2618', 'p13_reh7120', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 19 | ['p13_iqt9536', 'p13_bcc5520', 'p13_alx5039', 't11_taxm2203', 'p13_all5120', ...]\n",
      "\t\t('int', [])   : 13 | ['trended3d_tbca3275', 'p13_iqz9425', 'p13_iln8320', 'trended3d_tbca2618', 'p13_reh7120', ...]\n",
      "\t6.1s = Fit runtime\n",
      "\t32 features in original data used to generate 32 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 582.55 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 7.79s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting 2 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM ...\n",
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain_set's auc: 0.553224\ttrain_set's binary_logloss: 0.681828\tvalid_set's auc: 0.552421\tvalid_set's binary_logloss: 0.681978\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain_set's auc: 0.553224\ttrain_set's binary_logloss: 0.681828\tvalid_set's auc: 0.552421\tvalid_set's binary_logloss: 0.681978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[514]\ttrain_set's auc: 0.553517\ttrain_set's binary_logloss: 0.681783\tvalid_set's auc: 0.551981\tvalid_set's binary_logloss: 0.682036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\ttrain_set's auc: 0.552941\ttrain_set's binary_logloss: 0.681871\tvalid_set's auc: 0.55276\tvalid_set's binary_logloss: 0.681934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttrain_set's auc: 0.553108\ttrain_set's binary_logloss: 0.681846\tvalid_set's auc: 0.552236\tvalid_set's binary_logloss: 0.682003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[355]\ttrain_set's auc: 0.55311\ttrain_set's binary_logloss: 0.681841\tvalid_set's auc: 0.552621\tvalid_set's binary_logloss: 0.681956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain_set's auc: 0.553048\ttrain_set's binary_logloss: 0.681859\tvalid_set's auc: 0.552583\tvalid_set's binary_logloss: 0.681967\n",
      "Early stopping, best iteration is:\n",
      "[1106]\ttrain_set's auc: 0.55317\ttrain_set's binary_logloss: 0.681834\tvalid_set's auc: 0.552588\tvalid_set's binary_logloss: 0.681961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\ttrain_set's auc: 0.552719\ttrain_set's binary_logloss: 0.68192\tvalid_set's auc: 0.551841\tvalid_set's binary_logloss: 0.682073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[396]\ttrain_set's auc: 0.553308\ttrain_set's binary_logloss: 0.681795\tvalid_set's auc: 0.552538\tvalid_set's binary_logloss: 0.681955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[743]\ttrain_set's auc: 0.553293\ttrain_set's binary_logloss: 0.681814\tvalid_set's auc: 0.552554\tvalid_set's binary_logloss: 0.681955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain_set's auc: 0.552948\ttrain_set's binary_logloss: 0.681882\tvalid_set's auc: 0.552618\tvalid_set's binary_logloss: 0.681969\n",
      "Early stopping, best iteration is:\n",
      "[1210]\ttrain_set's auc: 0.55319\ttrain_set's binary_logloss: 0.68183\tvalid_set's auc: 0.552643\tvalid_set's binary_logloss: 0.681951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain_set's auc: 0.551847\ttrain_set's binary_logloss: 0.682361\tvalid_set's auc: 0.551478\tvalid_set's binary_logloss: 0.682418\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1957]\ttrain_set's auc: 0.552973\ttrain_set's binary_logloss: 0.681911\tvalid_set's auc: 0.552025\tvalid_set's binary_logloss: 0.682061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain_set's auc: 0.552827\ttrain_set's binary_logloss: 0.681904\tvalid_set's auc: 0.552679\tvalid_set's binary_logloss: 0.681965\n",
      "Early stopping, best iteration is:\n",
      "[1141]\ttrain_set's auc: 0.552995\ttrain_set's binary_logloss: 0.681869\tvalid_set's auc: 0.552708\tvalid_set's binary_logloss: 0.681953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain_set's auc: 0.553386\ttrain_set's binary_logloss: 0.681789\tvalid_set's auc: 0.552561\tvalid_set's binary_logloss: 0.681954\n",
      "Early stopping, best iteration is:\n",
      "[807]\ttrain_set's auc: 0.553129\ttrain_set's binary_logloss: 0.681842\tvalid_set's auc: 0.552614\tvalid_set's binary_logloss: 0.681958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain_set's auc: 0.553285\ttrain_set's binary_logloss: 0.681808\tvalid_set's auc: 0.552661\tvalid_set's binary_logloss: 0.681943\n",
      "Early stopping, best iteration is:\n",
      "[968]\ttrain_set's auc: 0.553252\ttrain_set's binary_logloss: 0.681816\tvalid_set's auc: 0.552668\tvalid_set's binary_logloss: 0.681944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[509]\ttrain_set's auc: 0.553185\ttrain_set's binary_logloss: 0.681824\tvalid_set's auc: 0.552598\tvalid_set's binary_logloss: 0.68195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain_set's auc: 0.553277\ttrain_set's binary_logloss: 0.681812\tvalid_set's auc: 0.552498\tvalid_set's binary_logloss: 0.681955\n",
      "Early stopping, best iteration is:\n",
      "[1063]\ttrain_set's auc: 0.55336\ttrain_set's binary_logloss: 0.681794\tvalid_set's auc: 0.552504\tvalid_set's binary_logloss: 0.68195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[310]\ttrain_set's auc: 0.55372\ttrain_set's binary_logloss: 0.68179\tvalid_set's auc: 0.551332\tvalid_set's binary_logloss: 0.682128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[292]\ttrain_set's auc: 0.55322\ttrain_set's binary_logloss: 0.681826\tvalid_set's auc: 0.55252\tvalid_set's binary_logloss: 0.681959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain_set's auc: 0.551631\ttrain_set's binary_logloss: 0.682152\tvalid_set's auc: 0.552029\tvalid_set's binary_logloss: 0.682123\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1029]\ttrain_set's auc: 0.551672\ttrain_set's binary_logloss: 0.682144\tvalid_set's auc: 0.552061\tvalid_set's binary_logloss: 0.682115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[608]\ttrain_set's auc: 0.553176\ttrain_set's binary_logloss: 0.681832\tvalid_set's auc: 0.552634\tvalid_set's binary_logloss: 0.681954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[726]\ttrain_set's auc: 0.553095\ttrain_set's binary_logloss: 0.68185\tvalid_set's auc: 0.552579\tvalid_set's binary_logloss: 0.681968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[602]\ttrain_set's auc: 0.55397\ttrain_set's binary_logloss: 0.681692\tvalid_set's auc: 0.55196\tvalid_set's binary_logloss: 0.682012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[978]\ttrain_set's auc: 0.55295\ttrain_set's binary_logloss: 0.681886\tvalid_set's auc: 0.552482\tvalid_set's binary_logloss: 0.681982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[199]\ttrain_set's auc: 0.553391\ttrain_set's binary_logloss: 0.681791\tvalid_set's auc: 0.552374\tvalid_set's binary_logloss: 0.681973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[1000]\ttrain_set's auc: 0.553261\ttrain_set's binary_logloss: 0.681814\tvalid_set's auc: 0.552688\tvalid_set's binary_logloss: 0.68194\n",
      "Early stopping, best iteration is:\n",
      "[995]\ttrain_set's auc: 0.553254\ttrain_set's binary_logloss: 0.681815\tvalid_set's auc: 0.552691\tvalid_set's binary_logloss: 0.68194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[395]\ttrain_set's auc: 0.55303\ttrain_set's binary_logloss: 0.681857\tvalid_set's auc: 0.552539\tvalid_set's binary_logloss: 0.681976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTime limit exceeded\n",
      "Fitted model: LightGBM/T0 ...\n",
      "\t0.5524\t = Validation score   (roc_auc)\n",
      "\t128.1s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitted model: LightGBM/T1 ...\n",
      "\t0.551\t = Validation score   (roc_auc)\n",
      "\t24.68s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitted model: LightGBM/T2 ...\n",
      "\t0.552\t = Validation score   (roc_auc)\n",
      "\t96.26s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitted model: LightGBM/T3 ...\n",
      "\t0.5486\t = Validation score   (roc_auc)\n",
      "\t28.84s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitted model: LightGBM/T4 ...\n",
      "\t0.5505\t = Validation score   (roc_auc)\n",
      "\t30.7s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitted model: LightGBM/T5 ...\n",
      "\t0.5509\t = Validation score   (roc_auc)\n",
      "\t33.48s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitted model: LightGBM/T6 ...\n",
      "\t0.5528\t = Validation score   (roc_auc)\n",
      "\t61.62s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitted model: LightGBM/T7 ...\n",
      "\t0.5522\t = Validation score   (roc_auc)\n",
      "\t59.24s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitted model: LightGBM/T8 ...\n",
      "\t0.5522\t = Validation score   (roc_auc)\n",
      "\t66.67s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitted model: LightGBM/T9 ...\n",
      "\t0.5526\t = Validation score   (roc_auc)\n",
      "\t71.27s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitted model: LightGBM/T10 ...\n",
      "\t0.5526\t = Validation score   (roc_auc)\n",
      "\t164.66s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitted model: LightGBM/T11 ...\n",
      "\t0.5518\t = Validation score   (roc_auc)\n",
      "\t45.4s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitted model: LightGBM/T12 ...\n",
      "\t0.5525\t = Validation score   (roc_auc)\n",
      "\t74.64s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitted model: LightGBM/T13 ...\n",
      "\t0.5515\t = Validation score   (roc_auc)\n",
      "\t15.12s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitted model: LightGBM/T14 ...\n",
      "\t0.5526\t = Validation score   (roc_auc)\n",
      "\t121.61s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitted model: LightGBM/T15 ...\n",
      "\t0.5526\t = Validation score   (roc_auc)\n",
      "\t177.76s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitted model: LightGBM/T16 ...\n",
      "\t0.552\t = Validation score   (roc_auc)\n",
      "\t252.74s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Fitted model: LightGBM/T17 ...\n",
      "\t0.5527\t = Validation score   (roc_auc)\n",
      "\t165.35s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitted model: LightGBM/T18 ...\n",
      "\t0.5526\t = Validation score   (roc_auc)\n",
      "\t124.34s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitted model: LightGBM/T19 ...\n",
      "\t0.5527\t = Validation score   (roc_auc)\n",
      "\t145.75s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitted model: LightGBM/T20 ...\n",
      "\t0.5526\t = Validation score   (roc_auc)\n",
      "\t86.81s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitted model: LightGBM/T21 ...\n",
      "\t0.5525\t = Validation score   (roc_auc)\n",
      "\t157.97s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitted model: LightGBM/T22 ...\n",
      "\t0.5513\t = Validation score   (roc_auc)\n",
      "\t69.69s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitted model: LightGBM/T23 ...\n",
      "\t0.5526\t = Validation score   (roc_auc)\n",
      "\t73.12s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitted model: LightGBM/T24 ...\n",
      "\t0.5525\t = Validation score   (roc_auc)\n",
      "\t61.45s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitted model: LightGBM/T25 ...\n",
      "\t0.5521\t = Validation score   (roc_auc)\n",
      "\t123.16s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitted model: LightGBM/T26 ...\n",
      "\t0.5524\t = Validation score   (roc_auc)\n",
      "\t38.35s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitted model: LightGBM/T27 ...\n",
      "\t0.5526\t = Validation score   (roc_auc)\n",
      "\t100.35s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitted model: LightGBM/T28 ...\n",
      "\t0.5526\t = Validation score   (roc_auc)\n",
      "\t110.46s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitted model: LightGBM/T29 ...\n",
      "\t0.552\t = Validation score   (roc_auc)\n",
      "\t77.98s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitted model: LightGBM/T30 ...\n",
      "\t0.5525\t = Validation score   (roc_auc)\n",
      "\t123.13s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitted model: LightGBM/T31 ...\n",
      "\t0.5524\t = Validation score   (roc_auc)\n",
      "\t50.2s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitted model: LightGBM/T32 ...\n",
      "\t0.5527\t = Validation score   (roc_auc)\n",
      "\t149.22s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitted model: LightGBM/T33 ...\n",
      "\t0.5525\t = Validation score   (roc_auc)\n",
      "\t73.87s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Hyperparameter tuning model: ExtraTrees ...\n",
      "Warning: Exception caused ExtraTrees to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 1155, in _train_single_full\n",
      "    hpo_models, hpo_model_performances, hpo_results = model.hyperparameter_tune(X=X, y=y, X_val=X_val, y_val=y_val, scheduler_options=hyperparameter_tune_kwargs, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 830, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(scheduler_options=scheduler_options, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/autogluon/tabular/models/rf/rf_model.py\", line 282, in _hyperparameter_tune\n",
      "    return skip_hpo(self, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/autogluon/core/models/abstract/model_trial.py\", line 98, in skip_hpo\n",
      "    fit_and_save_model(model=model, params=dict(), fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/autogluon/core/models/abstract/model_trial.py\", line 73, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left, reporter=reporter)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/autogluon/tabular/models/rf/rf_model.py\", line 107, in _fit\n",
      "    n_estimators_minimum = min(40, n_estimators_final)\n",
      "TypeError: '<' not supported between instances of 'Int' and 'int'\n",
      "'<' not supported between instances of 'Int' and 'int'\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 719.22s of the 3948.25s of remaining time.\n",
      "\t0.5528\t = Validation score   (roc_auc)\n",
      "\t89.71s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3357.87s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./artifacts/autogluon-prescreen/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = tp.fit(train_data=train_data, \n",
    "                     tuning_data=valid_data,\n",
    "                     time_limit=time_limits,\n",
    "                     hyperparameters={'GBM': gbm_options,\n",
    "#                                       'CAT': cat_options,\n",
    "                                      'XT': xgb_options\n",
    "                                     },\n",
    "                     hyperparameter_tune_kwargs='bayesopt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e19efe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2   0.552807       1.045775  300.554168                0.173214          89.710923            2       True         35\n",
      "1           LightGBM/T6   0.552760       0.321375   61.623524                0.321375          61.623524            1       True          7\n",
      "2          LightGBM/T17   0.552708       0.596124  165.350447                0.596124         165.350447            1       True         18\n",
      "3          LightGBM/T32   0.552691       0.551186  149.219721                0.551186         149.219721            1       True         33\n",
      "4          LightGBM/T19   0.552668       0.532320  145.746557                0.532320         145.746557            1       True         20\n",
      "5          LightGBM/T15   0.552643       0.602852  177.758395                0.602852         177.758395            1       True         16\n",
      "6          LightGBM/T27   0.552634       0.438978  100.351051                0.438978         100.351051            1       True         28\n",
      "7           LightGBM/T9   0.552621       0.324402   71.266328                0.324402          71.266328            1       True         10\n",
      "8          LightGBM/T18   0.552614       0.488672  124.335616                0.488672         124.335616            1       True         19\n",
      "9          LightGBM/T20   0.552598       0.381447   86.808461                0.381447          86.808461            1       True         21\n",
      "10         LightGBM/T23   0.552590       0.344214   73.116937                0.344214          73.116937            1       True         24\n",
      "11         LightGBM/T10   0.552588       0.577375  164.658633                0.577375         164.658633            1       True         11\n",
      "12         LightGBM/T28   0.552579       0.437049  110.456700                0.437049         110.456700            1       True         29\n",
      "13         LightGBM/T14   0.552554       0.570915  121.614301                0.570915         121.614301            1       True         15\n",
      "14         LightGBM/T33   0.552539       0.346455   73.873125                0.346455          73.873125            1       True         34\n",
      "15         LightGBM/T12   0.552538       0.345086   74.638249                0.345086          74.638249            1       True         13\n",
      "16         LightGBM/T24   0.552520       0.383986   61.450618                0.383986          61.450618            1       True         25\n",
      "17         LightGBM/T21   0.552504       0.759796  157.972311                0.759796         157.972311            1       True         22\n",
      "18         LightGBM/T30   0.552482       0.701856  123.129647                0.701856         123.129647            1       True         31\n",
      "19          LightGBM/T0   0.552421       0.702341  128.099868                0.702341         128.099868            1       True          1\n",
      "20         LightGBM/T26   0.552390       0.285979   38.346258                0.285979          38.346258            1       True         27\n",
      "21         LightGBM/T31   0.552374       0.304579   50.196838                0.304579          50.196838            1       True         32\n",
      "22          LightGBM/T8   0.552237       0.366773   66.668611                0.366773          66.668611            1       True          9\n",
      "23          LightGBM/T7   0.552236       0.379225   59.237854                0.379225          59.237854            1       True          8\n",
      "24         LightGBM/T25   0.552061       0.540848  123.155151                0.540848         123.155151            1       True         26\n",
      "25         LightGBM/T16   0.552025       1.430853  252.740072                1.430853         252.740072            1       True         17\n",
      "26          LightGBM/T2   0.551981       0.618548   96.261018                0.618548          96.261018            1       True          3\n",
      "27         LightGBM/T29   0.551960       0.625028   77.977917                0.625028          77.977917            1       True         30\n",
      "28         LightGBM/T11   0.551841       0.282756   45.401980                0.282756          45.401980            1       True         12\n",
      "29         LightGBM/T13   0.551533       0.249623   15.115784                0.249623          15.115784            1       True         14\n",
      "30         LightGBM/T22   0.551332       0.380718   69.685399                0.380718          69.685399            1       True         23\n",
      "31          LightGBM/T1   0.550963       0.266576   24.684578                0.266576          24.684578            1       True          2\n",
      "32          LightGBM/T5   0.550876       0.252415   33.481169                0.252415          33.481169            1       True          6\n",
      "33          LightGBM/T4   0.550539       0.256504   30.702696                0.256504          30.702696            1       True          5\n",
      "34          LightGBM/T3   0.548633       0.236739   28.837478                0.236739          28.837478            1       True          4\n",
      "Number of models trained: 35\n",
      "Types of models trained:\n",
      "{'LGBModel', 'WeightedEnsembleModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 19 | ['p13_iqt9536', 'p13_bcc5520', 'p13_alx5039', 't11_taxm2203', 'p13_all5120', ...]\n",
      "('int', [])   : 13 | ['trended3d_tbca3275', 'p13_iqz9425', 'p13_iln8320', 'trended3d_tbca2618', 'p13_reh7120', ...]\n",
      "Plot summary of models saved to file: ./artifacts/autogluon-prescreen/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "summary = predictor.fit_summary(2, show_plot=True);\n",
    "lb = predictor.leaderboard(valid_data, silent=True, extra_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c29893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = str(dt.datetime.now().timestamp()).split(\".\")[0]\n",
    "lb.to_csv(f\"./artifacts/autogluon_search_{time_str}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e3e0724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LightGBM/T6'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'num_boost_round': 1724,\n",
       " 'num_threads': 96,\n",
       " 'learning_rate': 0.09461497491247566,\n",
       " 'objective': 'binary',\n",
       " 'verbose': -1,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'two_round': True,\n",
       " 'metric': 'auc',\n",
       " 'boosting': 'gbdt',\n",
       " 'tree_learner': 'feature',\n",
       " 'boost_from_average': 'false',\n",
       " 'num_leaves': 68,\n",
       " 'lambda_l1': 20.282603527974402,\n",
       " 'lambda_l2': 1.0736675984836697,\n",
       " 'min_data_in_leaf': 50,\n",
       " 'max_depth': 2,\n",
       " 'feature_fraction': 0.15988559572182998,\n",
       " 'early_stopping_round': 200,\n",
       " 'seed': 42,\n",
       " 'seed_value': 42}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_hyperparams(predictor, model_type, leader_board=None):\n",
    "    \"\"\"\n",
    "    Get the hyperparams of the best model of <model_type> from AutoGluon predictor\n",
    "    \n",
    "    @returns model rank, model_params\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    if leader_board is None:\n",
    "        leader_board = predictor.leaderboard(extra_info=True, silent=True)\n",
    "    \n",
    "    for rank, row in lb.iterrows():\n",
    "        if model_type in row['model']:\n",
    "            return (rank, row['model'], row['hyperparameters'])\n",
    "    return (np.nan, \"No such model found\")\n",
    "\n",
    "model_rank, model_name, lgbm_params = get_best_hyperparams(predictor, model_type='LightGBM', leader_board=lb)\n",
    "display(model_name)\n",
    "lgbm_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2d1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f966dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
