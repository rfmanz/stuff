{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "047e1466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, json, os, ast\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from smart_open import open\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "\n",
    "sys.path.insert(1, \"../..\")\n",
    "from src.logger import make_logger\n",
    "from src.dataloader import TabularDataloader\n",
    "from src.Trainer import LGBMTrainer, TFTrainer\n",
    "from src.preprocess import Preprocess\n",
    "\n",
    "from rdsutils.feature_selection import mrmr\n",
    "from rdsutils.woe import WOE_Transform\n",
    "from _utils.feature_selection import feature_selection as fs\n",
    "from _utils.performance_eval import performance_eval_v3 as p_eval\n",
    "from rdsutils.feature_selection import FeatureSelector as general_purpose_fsel\n",
    "from src.feature_selection import FeatureSelector  # to be moved to rdsutils\n",
    "\n",
    "# new modules\n",
    "from _utils.sample_weights import get_sample_weight\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0964694d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'meta', 'data_columns', 'model_params', 'model_features', 'impute_vals', 'monotone'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = 'target_v1'\n",
    "target_indeterminate = 'indeterminate_v1'\n",
    "weight = \"weight\"\n",
    "seed = 42\n",
    "\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "display(config.keys()) \n",
    "\n",
    "gen3_features = config[\"data_columns\"][\"gen3_features\"]\n",
    "gen3_params = config[\"model_params\"][\"gen3_params\"]\n",
    "if \"scale_pos_weight\" in gen3_params:\n",
    "    del gen3_params[\"scale_pos_weight\"]\n",
    "\n",
    "bureau_fts = config[\"data_columns\"][\"bureau_features_cols\"] \n",
    "cat_fts = ['t11_t3d_segid', 't11_t3d_segid_supp'] # config[\"data_columns\"][\"cat_cols\"] \n",
    "prescreen_fts = bureau_fts + cat_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef78cd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all_features_dev1', 'all_features_dev2', 'all_features_oot1', 'all_features_oot2', 'subset_dev1', 'subset_dev2'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(config[\"data\"][\"clean\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5bd616",
   "metadata": {},
   "source": [
    "#### load data and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88c517a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.4 s, sys: 1min 19s, total: 1min 53s\n",
      "Wall time: 40 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((228188, 5131), (10000, 5131))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# data dict\n",
    "exp_dict = pd.read_csv(config[\"meta\"][\"exp_dict_path\"])\n",
    "\n",
    "# fsel data - sampled\n",
    "dl = TabularDataloader(train_path=config[\"data\"][\"clean\"][\"subset_dev1\"])\n",
    "dl.load_data(debug_size=10000, random_state=seed)\n",
    "\n",
    "debug_df, _, _ = dl.get_data(debug=True)\n",
    "train_df, _, _ = dl.get_data(debug=False)\n",
    "train_df.shape, debug_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746522c",
   "metadata": {},
   "source": [
    "#### get sample weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5084fae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4205/4205 [00:10<00:00, 414.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        added columns:\n",
      "            weight: training sample_weight scaled using provided weights by ri_source\n",
      "                weight_cob * weight_ri_v1 * weight_sample\n",
      "            weight_eval: weight_cob * weight_ri_v1\n",
      "                used for evaluation purposes\n",
      "        \n",
      "dropping indeterminate col: indeterminate_v1\n",
      "CPU times: user 14.9 s, sys: 4.94 s, total: 19.8 s\n",
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "col = \"ri_source\"\n",
    "weights = {\"booked\": 1,\n",
    "           \"proxy\": 1,\n",
    "           \"others\": 0.25}\n",
    "\n",
    "assert sorted(train_df[col].unique().tolist()) == sorted(list(weights.keys()))\n",
    "\n",
    "pp = Preprocess(exp_dict)\n",
    "\n",
    "train_df[\"weight_eval\"] = train_df[\"weight_cob\"] * train_df[\"weight_ri_v1\"]\n",
    "%time train_df = pp.transform(train_df, prescreen_fts, weights, drop_indeterminate=target_indeterminate, existing_weights_col=\"weight_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61c732e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ri_source\n",
       "booked    15610.0\n",
       "others    24218.0\n",
       "proxy     18196.0\n",
       "Name: weight, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ri_source\n",
       "booked    15610.0\n",
       "others    96872.0\n",
       "proxy     18196.0\n",
       "Name: weight_eval, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at weights\n",
    "display(train_df[[\"weight\", \"ri_source\"]].groupby(\"ri_source\")[\"weight\"].sum())\n",
    "display(train_df[[\"weight_eval\", \"ri_source\"]].groupby(\"ri_source\")[\"weight_eval\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f99828",
   "metadata": {},
   "source": [
    "#### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9df811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_col: target_v1\n",
      "weight_col: weight\n",
      "Preprocessing... generating iv and shaps\n",
      "prepping woe...\n",
      "\u001b[32mAttrs removed--missing pct>99%:  \u001b[0m ['p13_all8162', 'p13_all8163', 'p13_all8380', 'p13_all8723', 'p13_all9222', 'p13_all9223', 'p13_all9230', 'p13_all9239', 'p13_all9240', 'p13_all9249', 'p13_all9260', 'p13_all9280', 'p13_aua8162', 'p13_aua8163', 'p13_bca0401', 'p13_bca5021', 'p13_bca6201', 'p13_col8194', 'p13_hlc5021', 'p13_hlc7117', 'p13_iln0403', 'p13_mtf8169', 'p13_mtf8656', 'p13_mts8151', 'p13_rpm5020', 'p13_rpm5320', 'p13_rpm5820', 'p13_rpm6160', 'p13_rpm7110', 'p13_rti5020', 'p13_rti5320', 'p13_rti5820', 'p13_uti5030', 'p13_uti5530', 'p13_uti8151', 't11_tall1412', 't11_tall1413', 't11_tall2412', 't11_tcol2556', 't11_tcol2567', 't11_tcol3581', 't11_tmti0451', 't11_tmti0452', 't11_tmti0453', 't11_tmti0454', 't11_tmti0455', 't11_tmti0456', 't11_tmti0457', 't11_tmti0458', 't11_tstu0909']\n",
      "processed  4155  num attributes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepping lgbm shap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepping lgbm mc shap\n",
      "p13_all9130 1 no monotonic direction - probably should filter out\n",
      "p13_all9134 1 no monotonic direction - probably should filter out\n",
      "p13_all9135 1 no monotonic direction - probably should filter out\n",
      "p13_all9138 1 no monotonic direction - probably should filter out\n",
      "p13_all9139 1 no monotonic direction - probably should filter out\n",
      "p13_all9140 1 no monotonic direction - probably should filter out\n",
      "p13_all9141 1 no monotonic direction - probably should filter out\n",
      "p13_all9144 1 no monotonic direction - probably should filter out\n",
      "p13_all9145 1 no monotonic direction - probably should filter out\n",
      "p13_all9148 1 no monotonic direction - probably should filter out\n",
      "p13_all9149 1 no monotonic direction - probably should filter out\n",
      "p13_all9171 1 no monotonic direction - probably should filter out\n",
      "p13_all9177 1 no monotonic direction - probably should filter out\n",
      "p13_all9178 1 no monotonic direction - probably should filter out\n",
      "p13_all9180 1 no monotonic direction - probably should filter out\n",
      "p13_all9187 1 no monotonic direction - probably should filter out\n",
      "p13_all9188 1 no monotonic direction - probably should filter out\n",
      "p13_all9189 1 no monotonic direction - probably should filter out\n",
      "p13_all9330 1 no monotonic direction - probably should filter out\n",
      "p13_all9340 1 no monotonic direction - probably should filter out\n",
      "p13_all9380 1 no monotonic direction - probably should filter out\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering features by logic - experian\n",
      "dropping 530 features : kept 3675 features\n",
      "    reason:  not AA\n",
      "160 features with greater than                 0.95 missing values\n",
      "dropping 160 features : kept 3515 features\n",
      "    reason:  too many missing\n",
      "dropping 647 features : kept 2868 features\n",
      "    reason:  low_iv\n",
      "running many to few\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [09:27<00:00,  2.84s/it]\n",
      "100%|██████████| 200/200 [11:20<00:00,  3.40s/it]\n",
      "100%|██████████| 200/200 [22:44<00:00,  6.82s/it]\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ranking.csv\n",
      "running fsel on few\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "p13_all9130 1 no monotonic direction - probably should filter out\n",
      "p13_all9134 1 no monotonic direction - probably should filter out\n",
      "p13_all9135 1 no monotonic direction - probably should filter out\n",
      "p13_all9138 1 no monotonic direction - probably should filter out\n",
      "p13_all9139 1 no monotonic direction - probably should filter out\n",
      "p13_all9140 1 no monotonic direction - probably should filter out\n",
      "p13_all9141 1 no monotonic direction - probably should filter out\n",
      "p13_all9144 1 no monotonic direction - probably should filter out\n",
      "p13_all9145 1 no monotonic direction - probably should filter out\n",
      "p13_all9148 1 no monotonic direction - probably should filter out\n",
      "p13_all9149 1 no monotonic direction - probably should filter out\n",
      "p13_all9171 1 no monotonic direction - probably should filter out\n",
      "p13_all9177 1 no monotonic direction - probably should filter out\n",
      "p13_all9178 1 no monotonic direction - probably should filter out\n",
      "p13_all9180 1 no monotonic direction - probably should filter out\n",
      "p13_all9187 1 no monotonic direction - probably should filter out\n",
      "p13_all9188 1 no monotonic direction - probably should filter out\n",
      "p13_all9189 1 no monotonic direction - probably should filter out\n",
      "p13_all9330 1 no monotonic direction - probably should filter out\n",
      "p13_all9340 1 no monotonic direction - probably should filter out\n",
      "p13_all9380 1 no monotonic direction - probably should filter out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ranking.csv\n",
      "CPU times: user 1h 42min 43s, sys: 19min 58s, total: 2h 2min 41s\n",
      "Wall time: 1h 3min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# %%capture record\n",
    "\n",
    "nr_to_consider = 200\n",
    "nr_to_select = 50\n",
    "fsel_dir = \"./artifacts/dev1_fsel_1\"\n",
    "\n",
    "fsel = FeatureSelector(train_df, data_dict=exp_dict)\n",
    "rankings = fsel.run(prescreen_fts, target, weight, nr_to_consider, nr_to_select,\n",
    "                    output_dir=fsel_dir, filter_by_logic_expn=True)\n",
    "\n",
    "# with open(\"./artifacts/dev1_fsel_1/log.txt\", \"w\") as f:\n",
    "#     f.write(record.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e21149e",
   "metadata": {},
   "source": [
    "##### get fsel results\n",
    "\n",
    "* run `fsel.get_rankings(True)` to get ranking_df of features that is ever selected.\n",
    "\n",
    "\n",
    "##### if computation already made, we can just load it\n",
    "\n",
    "```python\n",
    "# initialte project and load back\n",
    "fsel = FeatureSelector(train_df, data_dict=exp_dict)\n",
    "fsel.load_state_dict(fsel_dir)\n",
    "```\n",
    "\n",
    "##### this is the logic underneath fsel.run\n",
    "\n",
    "```python\n",
    "# setup\n",
    "features = prescreen_fts\n",
    "target_col = target\n",
    "weight_col = weight\n",
    "output_dir = fsel_dir\n",
    "corr_threshold = 0.8\n",
    "filter_by_logic_expn = True\n",
    "\n",
    "# first preprocessing\n",
    "fsel.preprocess(features, target_col, weight_col, output_dir=output_dir)\n",
    "\n",
    "if filter_by_logic_expn:\n",
    "    print(\"filtering features by logic - experian\")\n",
    "    features = fsel.filter_by_logic_expn(features, target_col, weight_col)\n",
    "\n",
    "fsel.many_to_few(features, target_col, weight_col, nr_to_consider)\n",
    "if output_dir: fsel.save_state_dict(output_dir)\n",
    "\n",
    "# get top <nr_to_select> features by mean just as a rule of a thumb\n",
    "rankings_imp = fsel.get_rankings(True)\n",
    "rankings_imp[\"<mean>\"] = rankings_imp.mean(axis=1)\n",
    "rankings_imp.sort_values(\"<mean>\", inplace=True)\n",
    "top_features = rankings_imp.index.to_list()\n",
    "rankings_imp.drop(\"<mean>\", axis=1, inplace=True)\n",
    "\n",
    "# to approximate number of features to consider so\n",
    "# we end up nr_to_select features when using the less efficient \n",
    "# methods\n",
    "\n",
    "approx_nr_to_select = int(nr_to_select / (corr_threshold+0.001))\n",
    "\n",
    "fsel.fsel_on_few(top_features[:approx_nr_to_select], target_col, \n",
    "                 weight_col, corr_threshold=corr_threshold)\n",
    "if output_dir: fsel.save_state_dict(output_dir)\n",
    "\n",
    "rankings = fsel.get_rankings(False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d4aa1610",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsel2 = FeatureSelector(train_df, data_dict=exp_dict)\n",
    "fsel2.load_state_dict(output_dir)\n",
    "fts = fsel2.get_rankings(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc05857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b742c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9df7093b",
   "metadata": {},
   "source": [
    "#### build base model, set on features\n",
    "\n",
    "# issue: feature selector did not consider categorical variables.... since we only have < 5 of them, treat manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386ef99",
   "metadata": {},
   "source": [
    "#### hyperparam tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc2ca4",
   "metadata": {},
   "source": [
    "#### model eval\n",
    "---\n",
    "* evaluation segments\n",
    "    * `weight`\n",
    "    * around score cut\n",
    "    * booked, proxy, others"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pl_gen4",
   "language": "python",
   "name": "conda_pl_gen4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
