{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "---\n",
    "\n",
    "* backfill later from iter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time transactions_df = pd.read_parquet(\"../../data/joined/joined_1617834490/joined_1617834490.parquet\")\n",
    "\n",
    "existing_cols = transactions_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "sample = False\n",
    "id_col = 'business_account_number'\n",
    "id_token = \"<BUSINESS_ACCOUNT_NUMBER>\"\n",
    "if debug:\n",
    "    debug_ids = pd.read_csv('../../artifacts/debug_ids.csv')\n",
    "    debug_ids[id_token] = debug_ids[id_token].astype(transactions_df[id_col].dtype)\n",
    "    transactions_df = transactions_df[transactions_df[id_col].isin(debug_ids[id_token])]\n",
    "    # load ids\n",
    "    # filter by ids\n",
    "# debug version: load and filter by debug_ids \n",
    "elif sample:\n",
    "    transactions_df = transactions_df.sample(n=1000000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28260180, 109)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-04-07 01:27:37')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transactions_df.transaction_datetime.hist(bins=100)\n",
    "transactions_df.transaction_datetime.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly transactions amounts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1221399, 109)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = transactions_df[transactions_df.transaction_datetime.between(pd.to_datetime(\"2020-08-01\"),\n",
    "                                                                   pd.to_datetime(\"2020-08-31\"))]\n",
    "df_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add ID\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transactions_id(transactions_df):\n",
    "    transactions_df.sort_values(by=['business_account_number', \n",
    "                                    'transaction_datetime'],\n",
    "                                inplace=True)\n",
    "    transactions_df['group_rank'] = transactions_df.groupby('business_account_number')['transaction_datetime'].rank('first').astype(int)\n",
    "\n",
    "    # get id by combining bid, datatime, and rank\n",
    "    # actually need a way to order this key...\n",
    "    transactions_df['transaction_id'] = (transactions_df['business_account_number'].astype(str) \n",
    "                                         + '-' + transactions_df['transaction_datetime'].apply(lambda x: str(int(x.timestamp())))\n",
    "                                         + '-' + transactions_df['group_rank'].astype(str))\n",
    "    return transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    410000007044-1513182391-1\n",
       "1    410000007044-1513727720-2\n",
       "2    410000007044-1513727720-3\n",
       "3    410000007044-1513727720-4\n",
       "4    410000007044-1513727720-5\n",
       "Name: transaction_id, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df = get_transactions_id(transactions_df)\n",
    "\n",
    "transactions_df['transaction_id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28260180, (28260180, 111))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df['transaction_id'].nunique(), transactions_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move -f features over\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'odt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deposit_v2/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'odt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bffb30774474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m transactions_df['age_money_account'] = (transactions_df['transaction_datetime'] - \\\n\u001b[0;32m---> 13\u001b[0;31m                                         transactions_df['odt']).dt.days\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m transactions_df['lag_acc_open_first_transaction'] = (transactions_df['first_transaction_datetime'] - \\\n",
      "\u001b[0;32m~/anaconda3/envs/deposit_v2/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deposit_v2/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'odt'"
     ]
    }
   ],
   "source": [
    "# Sort data by transaction datetime.\n",
    "transactions_df = transactions_df.sort_values(by=['business_account_number', 'transaction_datetime'])\n",
    "\n",
    "### BANKING FEATURES\n",
    "transactions_df = pd.merge(transactions_df, \n",
    "                  transactions_df.groupby('business_account_number')['transaction_datetime'].min()\\\n",
    "                  .rename('first_transaction_datetime').to_frame(), \n",
    "                  how='left', on='business_account_number')\n",
    "transactions_df['days_since_first_deposit'] = (transactions_df['transaction_datetime'] - \\\n",
    "                                               transactions_df['first_transaction_datetime']).dt.days\n",
    "\n",
    "transactions_df['age_money_account'] = (transactions_df['transaction_datetime'] - \\\n",
    "                                        transactions_df['odt']).dt.days\n",
    "\n",
    "transactions_df['lag_acc_open_first_transaction'] = (transactions_df['first_transaction_datetime'] - \\\n",
    "                                                     transactions_df['odt']).dt.days\n",
    "\n",
    "transactions_df['first_deposit_amount'] = transactions_df['afdep'] #TODO: this is a waste of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREDIT FEATURES\n",
    "# No transformations on credit attributes at this time.\n",
    "# Eventually will transform because of default values.\n",
    "\n",
    "### GIACT FEATURES\n",
    "transactions_df['giact_time_since_first_link'] = (transactions_df['transaction_datetime'] - \\\n",
    "                                                  transactions_df['giact_first_link_date']).dt.days\n",
    "transactions_df['giact_time_since_last_link'] = (transactions_df['transaction_datetime'] - \\\n",
    "                                                 transactions_df['giact_last_link_date']).dt.days\n",
    "\n",
    "### TMX FEATURES\n",
    "# Nothing at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### External bank linkages:\n",
    "res = []\n",
    "curr = None\n",
    "counter = {}\n",
    "\n",
    "for row in tqdm(transactions_df[['business_account_number', 'transaction_datetime', \n",
    "                                 'external_account_number', 'external_institution_id', \n",
    "                                 'transaction_amount']].values):\n",
    "    if row[0] != curr:\n",
    "        curr = row[0]\n",
    "        counter = {}\n",
    "\n",
    "    if not row[2]:\n",
    "        res.append([None for i in range(6)])\n",
    "        continue\n",
    "\n",
    "    out = []\n",
    "\n",
    "    external_account_number = row[2]\n",
    "\n",
    "    if external_account_number not in counter:\n",
    "        counter[external_account_number] = {}\n",
    "\n",
    "    # nr past transactions with this account\n",
    "    if 'nr_trans_with_acc' in counter[external_account_number]:\n",
    "        counter[external_account_number]['nr_trans_with_acc'] += 1\n",
    "    else:\n",
    "        counter[external_account_number]['nr_trans_with_acc'] = 1\n",
    "    out.append(counter[external_account_number]['nr_trans_with_acc'] - 1)\n",
    "\n",
    "    # first transaction dt\n",
    "    if 'first_transaction_dt' not in counter[external_account_number]:\n",
    "        counter[external_account_number]['first_transaction_dt'] = row[1]\n",
    "    out.append(counter[external_account_number]['first_transaction_dt'])\n",
    "\n",
    "    # last transaction_dt\n",
    "    if 'last_transaction_dt' not in counter[external_account_number]:\n",
    "        counter[external_account_number]['last_transaction_dt'] = None\n",
    "    out.append(counter[external_account_number]['last_transaction_dt'])\n",
    "    counter[external_account_number]['last_transaction_dt'] = row[1]\n",
    "\n",
    "    # sum pos/neg transactions with acct\n",
    "    if 'sum_pos_trans' not in counter[external_account_number]:\n",
    "        counter[external_account_number]['sum_pos_trans'] = 0\n",
    "    if 'sum_neg_trans' not in counter[external_account_number]:\n",
    "        counter[external_account_number]['sum_neg_trans'] = 0\n",
    "    out.append(counter[external_account_number]['sum_pos_trans'])\n",
    "    out.append(counter[external_account_number]['sum_neg_trans'])\n",
    "\n",
    "    if row[4] >= 0:\n",
    "        counter[external_account_number]['sum_pos_trans'] += row[4]\n",
    "    else:\n",
    "        counter[external_account_number]['sum_neg_trans'] += row[4]\n",
    "\n",
    "    if 'rolling_mean_pos_trans' not in counter[external_account_number]:\n",
    "        counter[external_account_number]['rolling_mean_pos_trans'] = row[4]\n",
    "        out.append(None)\n",
    "    else:\n",
    "        out.append(counter[external_account_number]['rolling_mean_pos_trans'])\n",
    "        counter[external_account_number]['rolling_mean_pos_trans'] = (counter[external_account_number]['rolling_mean_pos_trans'] + row[4]) / 2\n",
    "\n",
    "    res.append(out)\n",
    "\n",
    "ea_cols = ['nr_trans_with_acc', 'first_trans_with_ea_dt', 'last_trans_with_ea_dt', 'sum_pos_trans_ea', 'sum_neg_trans_ea', 'rolling_mean_pos_trans_ea']\n",
    "transactions_df = transactions_df.assign(**dict.fromkeys(ea_cols, np.nan))\n",
    "transactions_df[ea_cols] = res\n",
    "\n",
    "del res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ea -> external account\n",
    "transactions_df['time_since_first_trans_ea'] = (transactions_df['transaction_datetime'] - transactions_df['first_trans_with_ea_dt']).dt.days\n",
    "transactions_df['time_since_last_trans_ea'] = (transactions_df['transaction_datetime'] - transactions_df['last_trans_with_ea_dt']).dt.days\n",
    "\n",
    "transactions_df['ratio_all_ea_trans_div_tamt'] = transactions_df['sum_pos_trans_ea'] / transactions_df['transaction_amount']\n",
    "transactions_df['ratio_rolling_mean_ea_tamt_div_tamt'] = transactions_df['rolling_mean_pos_trans_ea'] / transactions_df['transaction_amount']\n",
    "\n",
    "\n",
    "### TRANSACTION (not roll-ups) FEATURES\n",
    "transactions_df['transaction_as_pct_of_balance'] = transactions_df['transaction_amount'] / \\\n",
    "                                                   (transactions_df['real_ending_balance'] - \\\n",
    "                                                    transactions_df['transaction_amount'])\n",
    "\n",
    "transactions_df['last_transaction_datetime'] = transactions_df.groupby('business_account_number')['transaction_datetime'].shift(1)\n",
    "# transactions_df['last_transaction_code'] = transactions_df.groupby('business_account_number')['transaction_code'].shift(1)\n",
    "\n",
    "transactions_df['time_since_last_transaction'] = (transactions_df['transaction_datetime'] - \\\n",
    "                                                  transactions_df['last_transaction_datetime']).dt.seconds # this relies on transactions we don't like not being included!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multithreading workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def applyParallel(dfGrouped, func):\n",
    "    \"\"\" Helper to parallelize apply over groupby \"\"\"\n",
    "    with Pool(cpu_count()) as p:\n",
    "        ret_list = p.map(func, [group for name, group in dfGrouped])\n",
    "    return pd.concat(ret_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script manufactory\n",
    "def remove_breakers(s):\n",
    "    return \"\".join(\"\".join(s.split(\"\\n\")).split(\" \"))\n",
    "\n",
    "def get_kw_idx(L, kw):\n",
    "    for i, s in enumerate(L):\n",
    "        if s.startswith(kw):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def parallel_formatter(s, print_fn=True):\n",
    "    \"\"\"\n",
    "    works for the format:\n",
    "    df[] = df.groupby()[].func().values\n",
    "    \n",
    "    seems like functions that will benefit includes:\n",
    "    - rolling\n",
    "    - maybe expanding?\n",
    "    \n",
    "    doesnot work for cumcount - attribute of groupby\n",
    "    \"\"\"\n",
    "    # assert(check_format(s))\n",
    "    \n",
    "    s = remove_breakers(s).split(\".\")\n",
    "    \n",
    "    # get components\n",
    "    groupby_idx = get_kw_idx(s, \"groupby\")\n",
    "    values_idx = get_kw_idx(s, \"values\")\n",
    "    \n",
    "    # get func str parts\n",
    "    func_parts = s[groupby_idx+1:values_idx]\n",
    "    func_str = f\"\"\"def func(df_): return df_.{'.'.join(func_parts)}\"\"\"\n",
    "    \n",
    "    # get apply str parts\n",
    "    str_left = \".\".join(s[:groupby_idx+1])\n",
    "    setter_str, groupby_str = str_left.split(\"=\")\n",
    "    apply_str = f\"\"\"{setter_str}=applyParallel({groupby_str}, func).values\"\"\"\n",
    "    \n",
    "    result = \"\\n\".join([func_str, apply_str])\n",
    "    if print_fn:\n",
    "        print(result)\n",
    "    else:\n",
    "        return result\n",
    "    \n",
    "s = \"\"\"                                                         \n",
    "transactions_df['nr_transactions_3h'] = transactions_df.groupby('business_account_number') \\\n",
    "    .rolling('3h', min_periods=1, on='transaction_datetime')['is_trans'].sum().values\n",
    "|||\n",
    "transactions_df['nr_deposits_3h'] = transactions_df.groupby('business_account_number') \\\n",
    "    .rolling('3h', min_periods=1, on='transaction_datetime')['is_deposit'].sum().values\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# S = [s]\n",
    "S = s.split(\"|||\")\n",
    "for s in S:\n",
    "    parallel_formatter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.\n",
    "s = \"\"\"transactions_df['nr_returns_30d'] = transactions_df.groupby('business_account_number') \\\n",
    "                                                   .rolling('30d', min_periods=1, \\\n",
    "                                                            on='transaction_datetime') \\\n",
    "                                                    ['is_return'].sum().values\"\"\"\n",
    "parallel_formatter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions_df['nr_past_returns_'] = transactions_df.groupby('business_account_number')['is_return'].cumsum().values\n",
    "# def func(df_): return df_.cumsum()\n",
    "\n",
    "# transactions_df['nr_past_returns']=applyParallel(transactions_df.groupby('business_account_number')['is_return'], func).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To parallelize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # transaction features\n",
    "deposit_transaction_codes = ['POSDD', 'ACHDD', 'ACHDDIN', 'ACHINDD', 'DDCK', 'DDMBR', 'DD']\n",
    "withdrawal_transaction_codes = ['POSDW', 'ACHDW', 'ACHDWIN', 'DWATM', 'DWATMI', 'DWCK', 'DWBILLPAY',\n",
    "                                'DWCRDBILLPAY', 'DWMBR', 'ACHDWP2P', 'DWWIRE', 'DBDWWIRE', 'DWTRF', 'DBDW', 'DWSLROTP', 'DW']\n",
    "\n",
    "transactions_df['is_return'] = (transactions_df['transaction_code'].isin(['DWCKCB', 'DWACHRET', 'DDACHRET']) | \\\n",
    "                                      ((transactions_df['transaction_code'].isin(deposit_transaction_codes)) & \\\n",
    "                                       (transactions_df['transaction_amount'] < 0)))\n",
    "transactions_df['is_trans'] = transactions_df['transaction_code'].isin(deposit_transaction_codes + withdrawal_transaction_codes)\n",
    "transactions_df['is_deposit'] = transactions_df['transaction_code'].isin(deposit_transaction_codes) & \\\n",
    "                                (transactions_df['transaction_amount'] > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df['nr_past_returns'] = transactions_df.groupby('business_account_number')['is_return'].cumsum()\n",
    "\n",
    "def func(df_): return df_.rolling('30d',min_periods=1,on='transaction_datetime')['is_return'].sum()\n",
    "transactions_df['nr_returns_30d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "transactions_df['nr_past_deposits'] = transactions_df.groupby('business_account_number')['is_deposit'].cumsum()\n",
    "\n",
    "def func(df_): return df_.rolling('3d',min_periods=1,on='transaction_datetime')['is_deposit'].sum()\n",
    "transactions_df['nr_deposits_3d']=applyParallel(transactions_df.groupby('business_account_number'), func).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def func(df_): return df_.rolling('30d',min_periods=1,on='transaction_datetime')['is_deposit'].sum()\n",
    "transactions_df['nr_deposits_30d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('3d',min_periods=1,on='transaction_datetime')['is_trans'].sum()\n",
    "transactions_df['nr_transactions_3d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('30d',min_periods=1,on='transaction_datetime')['is_trans'].sum()\n",
    "transactions_df['nr_transactions_30d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "transactions_df['pct_returned_deposits'] = transactions_df['nr_past_returns'] / \\\n",
    "                                           transactions_df['nr_past_deposits']\n",
    "\n",
    "transactions_df['pct_returned_deposits_30d'] = transactions_df['nr_returns_30d'] / \\\n",
    "                                               transactions_df['nr_deposits_30d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# features cannot be parallelized that may take a while\n",
    "transactions_df['nr_past_transactions'] = transactions_df.groupby('business_account_number')['business_account_number'].cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "transactions_df['nr_transactions_30d_div_nr_past_transactions'] = transactions_df['nr_transactions_30d'] / transactions_df['nr_past_transactions']\n",
    "\n",
    "transactions_df['tamt_adjusted'] = transactions_df['transaction_amount'] * np.where(transactions_df['transaction_code'] == 'ACHDD', -1, 1)\n",
    "\n",
    "def func(df_): return df_.rolling('3d',min_periods=1,on='transaction_datetime')['real_ending_balance'].mean()\n",
    "transactions_df['mean_account_balance_3d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('30d',min_periods=1,on='transaction_datetime')['real_ending_balance'].mean()\n",
    "transactions_df['mean_account_balance_30d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "# def func(df_): return df_.rolling('3d',min_periods=1,on='transaction_datetime')['real_ending_balance'].std()\n",
    "# transactions_df['std_account_balance_3d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "# def func(df_): return df_.rolling('30d',min_periods=1,on='transaction_datetime')['real_ending_balance'].std()\n",
    "# transactions_df['std_account_balance_30d']=applyParallel(transactions_df.groupby('business_account_number'), func).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "transactions_df['deposit_transaction_amount'] = (transactions_df['is_deposit'] * transactions_df['transaction_amount']).replace(np.nan, 0)\n",
    "\n",
    "def func(df_): return df_.rolling('3d',min_periods=1,on='transaction_datetime')['deposit_transaction_amount'].sum()\n",
    "transactions_df['sum_deposits_3d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('10d',min_periods=1,on='transaction_datetime')['deposit_transaction_amount'].sum()\n",
    "transactions_df['sum_deposits_10d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('30d',min_periods=1,on='transaction_datetime')['deposit_transaction_amount'].sum()\n",
    "transactions_df['sum_deposits_30d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "\n",
    "transactions_df['is_withdrawal'] = transactions_df['transaction_code'].isin(withdrawal_transaction_codes) & \\\n",
    "                                   (transactions_df['transaction_amount'] < 0)\n",
    "transactions_df['withdrawal_transaction_amount'] = (transactions_df['is_withdrawal'] * transactions_df['transaction_amount']).replace(np.nan, 0)\n",
    "\n",
    "def func(df_): return df_.rolling('3d',min_periods=1,on='transaction_datetime')['withdrawal_transaction_amount'].sum()\n",
    "transactions_df['sum_withdrawals_3d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('10d',min_periods=1,on='transaction_datetime')['withdrawal_transaction_amount'].sum()\n",
    "transactions_df['sum_withdrawals_10d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('30d',min_periods=1,on='transaction_datetime')['withdrawal_transaction_amount'].sum()\n",
    "transactions_df['sum_withdrawals_30d']=applyParallel(transactions_df.groupby('business_account_number'), func).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "def func(df_): return df_.rolling('10d',min_periods=1,on='transaction_datetime')['deposit_transaction_amount'].mean()\n",
    "transactions_df['mean_deposits_10d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.expanding().mean()\n",
    "transactions_df['mean_deposits']=applyParallel(transactions_df.groupby('business_account_number')['deposit_transaction_amount'], func).values\n",
    "\n",
    "def func(df_): return df_.rolling('10d',min_periods=1,on='transaction_datetime')['withdrawal_transaction_amount'].mean()\n",
    "transactions_df['mean_withdrawals_10d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.expanding().mean()\n",
    "transactions_df['mean_withdrawals']=applyParallel(transactions_df.groupby('business_account_number')['withdrawal_transaction_amount'], func).values\n",
    "\n",
    "transactions_df['mean_deposits_10d_div_mean_deposits'] = transactions_df['mean_deposits_10d'] / transactions_df['mean_deposits']\n",
    "transactions_df['mean_withdrawals_10d_div_mean_withdrawals'] = transactions_df['mean_withdrawals_10d'] / transactions_df['mean_withdrawals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def func(df_): return df_.expanding().max()\n",
    "transactions_df['max_deposits']=applyParallel(transactions_df.groupby('business_account_number')['deposit_transaction_amount'], func).values\n",
    "\n",
    "def func(df_): return df_.rolling('3d',min_periods=1,on='transaction_datetime')['deposit_transaction_amount'].max()\n",
    "transactions_df['max_deposits_3d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('10d',min_periods=1,on='transaction_datetime')['deposit_transaction_amount'].max()\n",
    "transactions_df['max_deposits_10d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.expanding().max()\n",
    "transactions_df['max_withdrawals']=applyParallel(transactions_df.groupby('business_account_number')['withdrawal_transaction_amount'], func).values\n",
    "\n",
    "def func(df_): return df_.rolling('3d',min_periods=1,on='transaction_datetime')['withdrawal_transaction_amount'].min()\n",
    "transactions_df['max_withdrawals_3d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('10d',min_periods=1,on='transaction_datetime')['withdrawal_transaction_amount'].min()\n",
    "transactions_df['max_withdrawals_10d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "transactions_df['max_deposits_10d_div_mean_deposits'] = transactions_df['max_deposits_10d'] / transactions_df['mean_deposits']\n",
    "transactions_df['max_deposits_10d_div_mean_account_balance_30d'] = transactions_df['max_deposits_10d'] / transactions_df['mean_account_balance_30d']\n",
    "transactions_df['max_withdrawals_10d_div_mean_withdrawals'] = transactions_df['max_withdrawals_10d'] / transactions_df['mean_withdrawals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "transactions_df['nr_trans_ratio'] = transactions_df['nr_transactions_3d'] / transactions_df['nr_transactions_30d']\n",
    "transactions_df['bal_ratio'] = transactions_df['mean_account_balance_3d'] / transactions_df['mean_account_balance_30d']\n",
    "transactions_df['deposits_ratio'] = transactions_df['sum_deposits_3d'] / transactions_df['sum_deposits_30d']\n",
    "\n",
    "transactions_df['is_dd'] = transactions_df['transaction_code'] == 'ACHINDD'\n",
    "transactions_df['dd_dollar_amount'] = transactions_df['is_dd'] * transactions_df['transaction_amount']\n",
    "\n",
    "transactions_df['nr_direct_deposits'] = transactions_df.groupby('business_account_number')['is_dd'].cumsum()\n",
    "transactions_df['dollar_val_dd'] = transactions_df.groupby('business_account_number')['dd_dollar_amount'].cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "################################################\n",
    "#      DEPOSIT V1 features for bencharking: \n",
    "################################################\n",
    "def func(df_): return df_.rolling('14d',min_periods=1,on='transaction_datetime')['real_ending_balance'].mean()\n",
    "transactions_df['rolling_mean_acc_bal']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "# nr_transactions_per_day\n",
    "transactions_df['nr_past_transactions'] = transactions_df.groupby('business_account_number')\\\n",
    "                                            ['business_account_number'].cumcount()\n",
    "transactions_df['nr_transactions_per_day'] = transactions_df['nr_past_transactions'] / \\\n",
    "                                             transactions_df['days_since_first_deposit']\n",
    "\n",
    "# transaction_as_pct_of_balance\n",
    "transactions_df['transaction_as_pct_of_balance'] = transactions_df['transaction_amount'] / \\\n",
    "                                                   (transactions_df['real_ending_balance'] - \\\n",
    "                                                    transactions_df['transaction_amount'])\n",
    "\n",
    "# rolling_trns_as_pct_of_bal\n",
    "transactions_df['transaction_as_pct_of_balance_abs'] = transactions_df['transaction_as_pct_of_balance'].abs()\n",
    "\n",
    "def func(df_): return df_.rolling('7d',min_periods=1,on='transaction_datetime')['transaction_as_pct_of_balance_abs'].mean()\n",
    "transactions_df['rolling_trns_as_pct_of_bal']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "# transaction_as_pct_of_bal_min\n",
    "def func(df_): return df_.rolling('7d',min_periods=1,on='transaction_datetime')['transaction_as_pct_of_balance'].min()\n",
    "transactions_df['transaction_as_pct_of_bal_min']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "# rolling_mean_acc_bal <<< THIS IS WRONG? something going wrong!!\n",
    "def func(df_): return df_.rolling('14d',min_periods=1,on='transaction_datetime')['real_ending_balance'].mean()\n",
    "transactions_df['rolling_mean_acc_bal']=applyParallel(transactions_df.groupby('business_account_number'), func).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "####################################################################\n",
    "#    FEATURES FOR LABELING and DEBUGGING - has data snooping bias\n",
    "####################################################################\n",
    "transactions_df = pd.merge(transactions_df, \n",
    "                           transactions_df.groupby('business_account_number')['business_account_number'].count().rename('nr_transactions_all_time').reset_index(),\n",
    "                           how='inner',\n",
    "                           on='business_account_number')\n",
    "\n",
    "transactions_df = pd.merge(transactions_df, \n",
    "                           transactions_df[transactions_df['is_return']].groupby('business_account_number')['transaction_datetime'].min().rename('first_return_date').reset_index(),\n",
    "                           how='left',\n",
    "                           on='business_account_number')\n",
    "\n",
    "transactions_df = pd.merge(transactions_df, \n",
    "                           transactions_df[transactions_df['transaction_code'].isin(['DDCHGOFF', 'DDWRTOFF', 'DDFRDWO'])].groupby('business_account_number')['transaction_datetime'].min().rename('chg_wrt_off_date').reset_index(),\n",
    "                           how='left',\n",
    "                           on='business_account_number')\n",
    "\n",
    "transactions_df = pd.merge(transactions_df, \n",
    "                           transactions_df.groupby('business_account_number')['is_return'].sum().rename('nr_returns_all_time').reset_index(),\n",
    "                           how='inner',\n",
    "                           on='business_account_number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some more features\n",
    "---\n",
    "\n",
    "#### Shared by both ACH and MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "def func(df_): return df_.rolling('30d',min_periods=1,on='transaction_datetime')['withdrawal_transaction_amount'].min()\n",
    "transactions_df['max_withdrawals_30d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('30d',min_periods=1,on='transaction_datetime')['deposit_transaction_amount'].max()\n",
    "transactions_df['max_deposits_30d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "transactions_df['return_dollar_amount'] = transactions_df['is_return'] * transactions_df['tamt_adjusted']\n",
    "transactions_df['dollar_val_returns'] = transactions_df.groupby('business_account_number')['return_dollar_amount'].cumsum()\n",
    "\n",
    "def func(df_): return df_.rolling('3d',min_periods=1,on='transaction_datetime')['return_dollar_amount'].sum()\n",
    "transactions_df['dollar_val_returns_3d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "transactions_df['plaid_days_since_first_link'] = (transactions_df['transaction_datetime'] - \\\n",
    "                                                  transactions_df['plaid_first_link_date']).dt.days\n",
    "# transactions_df['quovo_days_since_first_link'] = (transactions_df['transaction_datetime'] - \\\n",
    "#                                                   transactions_df['quovo_first_link_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df['nr_days_to_chg_wrt_off'] = (transactions_df['chg_wrt_off_date'] - \n",
    "                                             transactions_df['transaction_datetime']).dt.days\n",
    "df_w_chg_off = transactions_df[~transactions_df.nr_days_to_chg_wrt_off.isna()]\n",
    "df_w_chg_off.nr_days_to_chg_wrt_off.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From MCD final push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit_transaction_codes = ['POSDD', 'ACHDD', 'ACHDDIN', 'ACHINDD', 'DDCK', 'DDMBR', 'DD']\n",
    "withdrawal_transaction_codes = ['POSDW', 'ACHDW', 'ACHDWIN', 'DWATM', 'DWATMI', 'DWCK', 'DWBILLPAY',\n",
    "                                'DWCRDBILLPAY', 'DWMBR', 'ACHDWP2P', 'DWWIRE', 'DBDWWIRE', 'DWTRF', 'DBDW', 'DWSLROTP', 'DW']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.sort_values(by=['business_account_number', 'transaction_datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test out expanding too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions_df['deposit_transaction_amount'] = (transactions_df['is_deposit'] * transactions_df['transaction_amount']).replace(np.nan, 0)\n",
    "\n",
    "# %time transactions_df['max_deposits'] = transactions_df.groupby('business_account_number')['deposit_transaction_amount'].expanding().max().values\n",
    "\n",
    "# def func(df_): return df_.expanding().max()\n",
    "# %time transactions_df['max_deposits_']=applyParallel(transactions_df.groupby('business_account_number')['deposit_transaction_amount'], func).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_absolute_error as mse\n",
    "\n",
    "# mse(transactions_df[\"max_deposits\"], transactions_df[\"max_deposits_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions_df[transactions_df[\"nr_past_returns_ach\"]>0][\"nr_past_returns_ach\"].hist(bins=100, alpha=0.5)\n",
    "# transactions_df[transactions_df[\"nr_past_returns_ach_\"]>0][\"nr_past_returns_ach_\"].hist(bins=100, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of different types of returns\n",
    "transactions_df['is_return_ach'] = transactions_df['transaction_code'].isin(['DWACHRET', 'DDACHRET'])\n",
    "transactions_df['is_return_mcd'] = transactions_df['transaction_code'].isin(['DWCKCB'])\n",
    "transactions_df['is_return_other'] = ((transactions_df['transaction_code'].isin(deposit_transaction_codes)) & \\\n",
    "                                       (transactions_df['transaction_amount'] < 0))\n",
    "\n",
    "# nr_past_return_types\n",
    "transactions_df['nr_past_returns_ach'] = transactions_df.groupby('business_account_number')['is_return_ach'].cumsum().values\n",
    "transactions_df['nr_past_returns_mcd'] = transactions_df.groupby('business_account_number')['is_return_mcd'].cumsum().values\n",
    "transactions_df['nr_past_returns_other'] = transactions_df.groupby('business_account_number')['is_return_other'].cumsum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# nr_returns_nd\n",
    "def func(df_): return df_.rolling('3d',min_periods=1,on='transaction_datetime')['is_return'].sum()\n",
    "transactions_df['nr_returns_3d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('3d',min_periods=1,on='transaction_datetime')['is_return_ach'].sum()\n",
    "transactions_df['nr_returns_ach_3d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('3d',min_periods=1,on='transaction_datetime')['is_return_mcd'].sum()\n",
    "transactions_df['nr_returns_mcd_3d']=applyParallel(transactions_df.groupby('business_account_number'), func).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# bouncing streaks\n",
    "deposit_transaction_codes = ['POSDD', 'ACHDD', 'ACHDDIN', 'ACHINDD', 'DDCK', 'DDMBR', 'DD']\n",
    "\n",
    "condition = (transactions_df['transaction_code'].isin(deposit_transaction_codes) |\n",
    "             transactions_df['is_return'])\n",
    "df_temp = transactions_df[condition][['transaction_id', \n",
    "                                      'business_account_number', \n",
    "                                      'transaction_datetime',\n",
    "                                      'is_return']]\n",
    "df_temp.sort_values(['business_account_number', 'transaction_datetime'], inplace=True)\n",
    "# out of past 5 deposit related transactions, how many were returns\n",
    "def func(df_): return df_.rolling(5,min_periods=1)['is_return'].mean()\n",
    "df_temp['rolling_deposit_returns']=applyParallel(df_temp.groupby('business_account_number'), func).values\n",
    "\n",
    "transactions_df = pd.merge(transactions_df, df_temp[['transaction_id', 'rolling_deposit_returns']], \n",
    "                           how='left', on='transaction_id')\n",
    "transactions_df['rolling_deposit_returns'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple small deposits then a big one\n",
    "\n",
    "s = transactions_df['deposit_transaction_amount']\n",
    "transactions_df[s.between(1,s.quantile(0.95))]['deposit_transaction_amount'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = transactions_df['deposit_transaction_amount'] > 0\n",
    "meta_cols = ['transaction_id', \n",
    "             'business_account_number', \n",
    "             'transaction_datetime',\n",
    "             'deposit_transaction_amount']\n",
    "df_temp = transactions_df[condition][meta_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# captures small, small, large pattern\n",
    "def func(df_): return df_.rolling(3,min_periods=1)['deposit_transaction_amount'].median()\n",
    "df_temp['median_deposits_last_3']=applyParallel(df_temp.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling(5,min_periods=1)['deposit_transaction_amount'].median()\n",
    "df_temp['median_deposits_last_5']=applyParallel(df_temp.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling(10,min_periods=1)['deposit_transaction_amount'].median()\n",
    "df_temp['median_deposits_last_10']=applyParallel(df_temp.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling(3,min_periods=1)['deposit_transaction_amount'].mean()\n",
    "df_temp['mean_deposits_last_3']=applyParallel(df_temp.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling(5,min_periods=1)['deposit_transaction_amount'].mean()\n",
    "df_temp['mean_deposits_last_5']=applyParallel(df_temp.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling(10,min_periods=1)['deposit_transaction_amount'].mean()\n",
    "df_temp['mean_deposits_last_10']=applyParallel(df_temp.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling(3,min_periods=1)['deposit_transaction_amount'].max()\n",
    "df_temp['max_deposits_last_3']=applyParallel(df_temp.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling(5,min_periods=1)['deposit_transaction_amount'].max()\n",
    "df_temp['max_deposits_last_5']=applyParallel(df_temp.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling(10,min_periods=1)['deposit_transaction_amount'].max()\n",
    "df_temp['max_deposits_last_10']=applyParallel(df_temp.groupby('business_account_number'), func).values\n",
    "\n",
    "\n",
    "df_temp['deposits_trend_short1'] = df_temp['max_deposits_last_3'] - df_temp['median_deposits_last_5']\n",
    "df_temp['deposits_trend_ratio_short1'] = df_temp['max_deposits_last_3'] / df_temp['median_deposits_last_5']\n",
    "df_temp['deposits_trend_mid1'] = df_temp['max_deposits_last_3'] - df_temp['median_deposits_last_10']\n",
    "df_temp['deposits_trend_ratio_mid1'] = df_temp['max_deposits_last_3'] / df_temp['median_deposits_last_10']\n",
    "df_temp['deposits_trend_mid2'] = df_temp['mean_deposits_last_3'] - df_temp['median_deposits_last_10']\n",
    "df_temp['deposits_trend_ratio_mid2'] = df_temp['mean_deposits_last_3'] / df_temp['median_deposits_last_10']\n",
    "\n",
    "new_cols = [f for f in df_temp.columns if f not in meta_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.merge(transactions_df, df_temp[new_cols+['transaction_id']], \n",
    "                           how='left', on='transaction_id')\n",
    "transactions_df[new_cols].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nr_deposits, nr_transactions over a period; and their ratios\n",
    "\n",
    "def func(df_): return df_.rolling('24h',min_periods=1,on='transaction_datetime')['is_trans'].sum()\n",
    "transactions_df['nr_transactions_1d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('24h',min_periods=1,on='transaction_datetime')['is_deposit'].sum()\n",
    "transactions_df['nr_deposits_1d']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "transactions_df['nr_deposits_ratio_1d'] = transactions_df['nr_deposits_1d'] / transactions_df['nr_transactions_1d']\n",
    "\n",
    "def func(df_): return df_.rolling('3h',min_periods=1,on='transaction_datetime')['is_trans'].sum()\n",
    "transactions_df['nr_transactions_3h']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "def func(df_): return df_.rolling('3h',min_periods=1,on='transaction_datetime')['is_deposit'].sum()\n",
    "transactions_df['nr_deposits_3h']=applyParallel(transactions_df.groupby('business_account_number'), func).values\n",
    "\n",
    "transactions_df['nr_deposits_ratio_3h'] = transactions_df['nr_deposits_3h'] / transactions_df['nr_transactions_3h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = transactions_df['nr_deposits_3h'] \n",
    "s.hist(bins=100)\n",
    "plt.show()\n",
    "transactions_df[s.between(s.quantile(0.01), s.quantile(0.99))]['nr_transactions_1d'].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = [f for f in transactions_df.columns if f not in existing_cols]\n",
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.to_parquet('../../artifacts/final/transactions_df_w_new_features.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ACH_labels\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from pandas.tseries.offsets import BDay\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "\n",
    "### Helper functions\n",
    "def reverse_df(df):\n",
    "    \"\"\" Helper for forward looking rolling function \"\"\"\n",
    "    # reverse dataset\n",
    "    reverse_df = df.iloc[::-1]\n",
    "    ri = reverse_df.index\n",
    "\n",
    "    # re-reverse index\n",
    "    reverse_df.index = ri[0] - ri + ri[-1]\n",
    "\n",
    "    return reverse_df\n",
    "\n",
    "## Need to define forward looking roll-ups at top level to parallelize.\n",
    "\n",
    "# df['nr_returns_in_next_5d'] = applyParallel(df[['business_account_number', \n",
    "#                                                 'is_return']].groupby('business_account_number'), \n",
    "#                                             get_nr_returns_5d).values\n",
    "\n",
    "def get_nr_returns_5d(df):\n",
    "    return reverse_df(reverse_df(df).rolling('5d', min_periods=1)['is_return'].sum())\n",
    "\n",
    "def get_bal_after_5d(df):\n",
    "    return reverse_df(reverse_df(df).rolling('5d', min_periods=1)['real_ending_balance'].apply(lambda a: a[0], raw=True))\n",
    "\n",
    "def applyParallel(dfGrouped, func):\n",
    "    \"\"\" Helper to parallelize apply over groupby \"\"\"\n",
    "    with Pool(cpu_count()) as p:\n",
    "        ret_list = p.map(func, [group for name, group in dfGrouped])\n",
    "    return pd.concat(ret_list)\n",
    "\n",
    "def stupid_hack(x):\n",
    "    try:\n",
    "        return x[-1]\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "\n",
    "def match_ach_returns(df, timedelta=BDay(3)):\n",
    "    \"\"\"\n",
    "    Check if ACH transactions are returned with some timeframe.\n",
    "    \"\"\"\n",
    "    #For performance purposes...\n",
    "    df = df[df['transaction_code'].isin(['ACHDD', 'DWACHRET'])]\n",
    "    \n",
    "    # df = df.reset_index(drop=True)\n",
    "\n",
    "    df['tamt_abs'] = df['transaction_amount'].abs()\n",
    "    df['is_returned'] = False\n",
    "    \n",
    "    for act_n, transaction in tqdm(df[df['is_return'] == 1].iterrows()):\n",
    "        \n",
    "        tdt_hi = transaction['transaction_datetime']\n",
    "        tdt_lo = tdt_hi - timedelta\n",
    "\n",
    "        dcandidate = df[df['business_account_number'] == transaction['business_account_number']]\n",
    "\n",
    "        dret = dcandidate[(dcandidate['transaction_datetime'].between(tdt_lo, tdt_hi)) & \\\n",
    "                          (dcandidate['tamt_abs'] == transaction['tamt_abs'])]\n",
    "        \n",
    "        df.loc[dret.index, 'is_returned'] = True\n",
    "\n",
    "#     df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def get_labels(df):\n",
    "    \"\"\"\n",
    "    Get add labels to processed data.\n",
    "    \"\"\"    \n",
    "    # sort data for roll-ups\n",
    "    df = df.sort_values(by=['business_account_number', 'transaction_datetime'])\n",
    "\n",
    "    df['days_to_acc_close'] = (pd.to_datetime(df['dtc']) - df['transaction_datetime']).dt.days\n",
    "    df['account_closed_by_risk_in_next_90d'] = df['closed_reason'].isin(['Closed by SoFi - Risk Request', \n",
    "                                                                         'Closed by SoFi - Charge-Off / Write-Off']) &\\\n",
    "                                               (df['days_to_acc_close'] <= 90)\n",
    "    \n",
    "    # does account chg/wrt off in next 90 days?\n",
    "    df['is_chg_wrt_off_in_90d'] = (df['chg_wrt_off_date'] - df['transaction_datetime']).dt.days <= 90\n",
    "\n",
    "    # Set index to transaction datetime.\n",
    "    df = df.set_index('transaction_datetime')\n",
    "\n",
    "    # get num returns by borrower in the next 90 days\n",
    "    df['nr_returns_in_next_5d'] = applyParallel(df[['business_account_number', 'is_return']].groupby('business_account_number'), get_nr_returns_5d).values\n",
    "    \n",
    "    # get this borrower's account balance after 90 days\n",
    "    df['bal_after_5d'] = applyParallel(df[['business_account_number', 'real_ending_balance']].groupby('business_account_number'), get_bal_after_5d).values\n",
    "\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    if 'level_0' in df.columns:\n",
    "        df = df.drop('level_0', axis=1)\n",
    "    \n",
    "    return df  \n",
    "\n",
    "\n",
    "# drop non ACH types\n",
    "def drop_non_ach(df):\n",
    "    df = df[df['transaction_code'].isin(['ACHDD']) & (df['transaction_amount'] > 0)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \"\"\"\n",
    "business_account_number\n",
    "transaction_datetime\n",
    "dtc\n",
    "closed_reason\n",
    "chg_wrt_off_date\n",
    "is_return\n",
    "real_ending_balance\n",
    "transaction_code\n",
    "transaction_amount\n",
    "\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting features that will be used for labels\n",
    "%time transactions_df_ = get_labels(transactions_df[cols])\n",
    "transactions_df_.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# match ach returns to get is_returned\n",
    "%time transactions_df__ = match_ach_returns(transactions_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.shape, transactions_df_.shape, transactions_df__.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.index.max(), transactions_df_.index.max(), transactions_df__.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df_by_idx(df1, df2):\n",
    "    for col in df2.columns:\n",
    "        idx = df2.index\n",
    "        if col in df1.columns:\n",
    "            print(f\"column {col} equals? {df1.loc[idx, col].equals(df2[col])}\")\n",
    "        else:\n",
    "            print(f\"adding column {col}\")\n",
    "            df1[col] = np.nan\n",
    "            df1.loc[idx, col] = df2[col]\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join labeled dfs with \n",
    "transactions_df = combine_df_by_idx(transactions_df, transactions_df_)\n",
    "transactions_df = combine_df_by_idx(transactions_df, transactions_df__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output as unlabeled...\n",
    "transactions_df.to_parquet('../../artifacts/final/transactions_df_labeled_ach.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add MCD label\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import BDay\n",
    "from tqdm import tqdm\n",
    "\n",
    "def reverse_df(df):\n",
    "    \"\"\" Helper for forward looking rolling function \"\"\"\n",
    "    # reverse dataset\n",
    "    reverse_df = df.iloc[::-1]\n",
    "    ri = reverse_df.index\n",
    "\n",
    "    # re-reverse index\n",
    "    reverse_df.index = ri[0] - ri + ri[-1]\n",
    "\n",
    "    return reverse_df\n",
    "\n",
    "NDAYS = 90\n",
    "\n",
    "def get_nr_returns_nd(df):\n",
    "    global NDAYS\n",
    "    return reverse_df(reverse_df(df).rolling(f'{NDAYS}d', min_periods=1)['is_return'].sum())\n",
    "\n",
    "def get_bal_after_nd(df):\n",
    "    global NDAYS\n",
    "    return reverse_df(reverse_df(df).rolling(f'{NDAYS}d', min_periods=1)['real_ending_balance'].apply(lambda a: a[0], raw=True))\n",
    "\n",
    "def applyParallel(dfGrouped, func):\n",
    "    \"\"\" Helper to parallelize apply over groupby \"\"\"\n",
    "    with Pool(cpu_count()) as p:\n",
    "        ret_list = p.map(func, [group for name, group in dfGrouped])\n",
    "    return pd.concat(ret_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def get_labels_nd(df, n_days=90):\n",
    "    \"\"\"\n",
    "    Get add labels to processed data.\n",
    "    \"\"\"\n",
    "    # sort data for roll-ups\n",
    "    global NDAYS\n",
    "    NDAYS = n_days\n",
    "    print(f'Ndays = {NDAYS}')\n",
    "    \n",
    "    # sort data for roll-ups\n",
    "    \n",
    "        \n",
    "\n",
    "#     df['days_to_acc_close'] = (pd.to_datetime(df['dtc']) - df['transaction_datetime']).dt.days\n",
    "    df[f'account_closed_by_risk_in_next_{n_days}d'] = df['closed_reason'].isin(['Closed by SoFi - Risk Request', \n",
    "                                                                         'Closed by SoFi - Charge-Off / Write-Off']) &\\\n",
    "                                               (df['days_to_acc_close'] <= n_days)\n",
    "    \n",
    "#     df['last_unrestricted_date_in_next_90d'] = (df['last_unrestricted_date'] - df['transaction_datetime']).dt.days.between(0, 90)\n",
    "    \n",
    "    # get most recent account balance\n",
    "    df = pd.merge(df, \n",
    "                  df.groupby('business_account_number')['real_ending_balance'].last().rename('latest_acc_bal').reset_index(),\n",
    "                  how='left', on='business_account_number')\n",
    "\n",
    "    # does account chg/wrt off in next n days?\n",
    "    df[f'is_chg_wrt_off_in_{n_days}d'] = (df['chg_wrt_off_date'] - df['transaction_datetime']).dt.days <= n_days\n",
    "\n",
    "    # Set index to transaction datetime.\n",
    "    df = df.set_index('transaction_datetime')\n",
    "\n",
    "    df[f'bal_after_{n_days}d'] = applyParallel(df[['business_account_number', \n",
    "                                           'real_ending_balance']].groupby('business_account_number'), \n",
    "                                                     get_bal_after_nd).values\n",
    "    df[f'nr_returns_in_next_{n_days}d'] = applyParallel(df[['business_account_number', \n",
    "                                                    'is_return']].groupby('business_account_number'), \n",
    "                                                 get_nr_returns_nd).values\n",
    "    df = df.reset_index()\n",
    "                \n",
    "    # drop non check types\n",
    "    \n",
    "    \n",
    "    def get_target(df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        df[f'target_{n_days}d'] = df[f'is_chg_wrt_off_in_{n_days}d'] | \\\n",
    "                       df[f'account_closed_by_risk_in_next_{n_days}d'] | \\\n",
    "                       (df[f'nr_returns_in_next_{n_days}d'] > 0) | \\\n",
    "                       (df[f'bal_after_{n_days}d'] < 0)\n",
    "        \n",
    "        df[f'indeterminate_{n_days}d'] = (df[f'target_{n_days}d'] & (df[f'bal_after_{n_days}d'] > 0)) | \\\n",
    "                              (~df[f'target_{n_days}d'] & (df[f'bal_after_{n_days}d'] <= 0))\n",
    "        \n",
    "        return df\n",
    "\n",
    "    df = get_target(df)\n",
    "\n",
    "    return df #.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dfs(df):\n",
    "    df.sort_values(by=['business_account_number', 'transaction_datetime', 'transaction_amount'], inplace=True)\n",
    "\n",
    "def drop_non_check(df):\n",
    "    df = df[df['transaction_code'].isin(['DDCK']) & (df['transaction_amount'] > 0)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_dfs(transactions_df)\n",
    "\n",
    "for n in tqdm([10, 30, 60]):\n",
    "    transactions_df = get_labels_nd(transactions_df, n_days=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.columns[transactions_df.columns.str.contains('target')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.to_parquet('../../artifacts/final/transactions_df_labeled_all.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [f for f in transactions_df.columns if f not in existing_cols]\n",
    "len(new_cols), new_cols[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load things back.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_parquet(\"../../artifacts/final/transactions_df_labeled_all.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df['time_since_last_transaction'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ml_basic_py37",
   "language": "python",
   "name": "conda_ml_basic_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
